import os
import torch
import torch.nn as nn
import numpy as np
import cv2
from pathlib import Path
from ultralytics import YOLO
from ultralytics.utils import LOGGER
from ultralytics.utils.loss import v8DetectionLoss  # ì‹¤ì œ YOLO ì†ì‹¤ í•¨ìˆ˜
import yaml
import glob
from torch.utils.data import Dataset, DataLoader
import matplotlib.pyplot as plt
from tqdm import tqdm
import json
from datetime import datetime

# Configuration
NUM_SLICES = 9
TARGET_SIZE = 960

class MultiSlice25DDataset(Dataset):
    """2.5D YOLO í›ˆë ¨ì„ ìœ„í•œ ë©€í‹°ìŠ¬ë¼ì´ìŠ¤ ë°ì´í„°ì…‹"""

    def __init__(self, img_path, imgsz=960, num_slices=9, mode='train', augment=False):
        self.img_path = img_path
        self.imgsz = imgsz
        self.num_slices = num_slices
        self.mode = mode
        self.augment = augment

        self.img_files = self._get_img_files()
        self.label_files = self._get_label_files()

        print(f"[{mode.upper()}] ë°œê²¬ëœ .npy íŒŒì¼: {len(self.img_files)}ê°œ")
        print(f"[{mode.upper()}] ë°œê²¬ëœ ë¼ë²¨ íŒŒì¼: {len(self.label_files)}ê°œ")

    def _get_img_files(self):
        if not os.path.exists(self.img_path):
            return []
        pattern = os.path.join(self.img_path, "*.npy")
        return sorted(glob.glob(pattern))

    def _get_label_files(self):
        label_files = []
        for img_file in self.img_files:
            label_file = img_file.replace('/images/', '/labels/').replace('.npy', '.txt')
            label_files.append(label_file)
        return label_files

    def __len__(self):
        return len(self.img_files)

    def _load_labels(self, label_path):
        """YOLO í˜•ì‹ ë¼ë²¨ ë¡œë“œ"""
        labels = []
        if os.path.exists(label_path):
            with open(label_path, 'r') as f:
                for line in f.readlines():
                    line = line.strip()
                    if line:
                        parts = line.split()
                        if len(parts) >= 5:
                            class_id = int(parts[0])
                            x_center = float(parts[1])
                            y_center = float(parts[2])
                            width = float(parts[3])
                            height = float(parts[4])
                            labels.append([class_id, x_center, y_center, width, height])
        return labels

    def _apply_augmentation(self, volume, labels):
        """ê°„ë‹¨í•œ ë°ì´í„° ì¦ê°• (negative stride ë¬¸ì œ í•´ê²°ë¨)"""
        if not self.augment or self.mode != 'train':
            return volume, labels

        # ëœë¤ í”Œë¦½ (copy()ë¡œ negative stride í•´ê²°)
        if np.random.random() > 0.5:
            volume = np.fliplr(volume).copy()  # .copy() ì¶”ê°€ë¡œ negative stride í•´ê²°
            # ë¼ë²¨ì˜ x ì¢Œí‘œë„ í”Œë¦½
            for label in labels:
                label[1] = 1.0 - label[1]  # x_center flip

        # ëœë¤ íšŒì „ (ì‘ì€ ê°ë„)
        if np.random.random() > 0.7:
            angle = np.random.uniform(-5, 5)
            center = (volume.shape[1]//2, volume.shape[0]//2)

            # ê° ìŠ¬ë¼ì´ìŠ¤ì— ëŒ€í•´ íšŒì „ ì ìš©
            rotated_slices = []
            for k in range(volume.shape[2]):
                M = cv2.getRotationMatrix2D(center, angle, 1.0)
                rotated_slice = cv2.warpAffine(volume[:, :, k], M, (volume.shape[1], volume.shape[0]))
                rotated_slices.append(rotated_slice)
            volume = np.stack(rotated_slices, axis=2)

        # ì•ˆì „ì„ ìœ„í•´ ìµœì¢…ì ìœ¼ë¡œ copy() ì ìš©
        volume = volume.copy()

        return volume, labels

    def __getitem__(self, idx):
        """ì•ˆì „í•œ ìƒ˜í”Œ ë¡œë“œ (negative stride ë¬¸ì œ ì™„ì „ í•´ê²°)"""
        try:
            # ë³¼ë¥¨ ë¡œë“œ
            volume = np.load(self.img_files[idx])

            # ì¦‰ì‹œ copy()ë¡œ ì•ˆì „í•œ ë°°ì—´ ë§Œë“¤ê¸°
            volume = np.array(volume, copy=True)

            # í˜•íƒœ ì²˜ë¦¬
            if len(volume.shape) == 2:
                volume = np.expand_dims(volume, axis=-1)

            # ìŠ¬ë¼ì´ìŠ¤ ìˆ˜ ë§ì¶”ê¸°
            if volume.shape[2] != self.num_slices:
                if volume.shape[2] == 1:
                    volume = np.repeat(volume, self.num_slices, axis=2)
                elif volume.shape[2] > self.num_slices:
                    volume = volume[:, :, :self.num_slices].copy()
                else:
                    last_slice = volume[:, :, -1:]
                    padding_needed = self.num_slices - volume.shape[2]
                    padding = np.repeat(last_slice, padding_needed, axis=2)
                    volume = np.concatenate([volume, padding], axis=2).copy()

            # ì •ê·œí™”
            if volume.max() > 1:
                volume = volume.astype(np.float32) / 255.0
            else:
                volume = volume.astype(np.float32)

            # ë°°ì—´ì´ ì—°ì†ì ì¸ì§€ í™•ì¸
            if not volume.flags['C_CONTIGUOUS']:
                volume = np.ascontiguousarray(volume)

            # í¬ê¸° ì¡°ì • (ê° ìŠ¬ë¼ì´ìŠ¤ë¥¼ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬)
            if volume.shape[0] != self.imgsz or volume.shape[1] != self.imgsz:
                resized_slices = []
                for k in range(self.num_slices):
                    slice_2d = np.ascontiguousarray(volume[:, :, k])
                    resized_slice = cv2.resize(slice_2d, (self.imgsz, self.imgsz))
                    resized_slices.append(resized_slice)
                volume = np.stack(resized_slices, axis=-1)
                volume = np.ascontiguousarray(volume)

            # ë¼ë²¨ ë¡œë“œ
            labels = self._load_labels(self.label_files[idx])

            # ë°ì´í„° ì¦ê°• ì ìš©
            volume, labels = self._apply_augmentation(volume, labels)

            # ìµœì¢… ì•ˆì „ì„± í™•ì¸
            volume = np.ascontiguousarray(volume)

            # (C, H, W) í˜•íƒœë¡œ ë³€í™˜
            img_tensor = torch.from_numpy(volume).permute(2, 0, 1).float()

            # ë¼ë²¨ì„ í…ì„œë¡œ ë³€í™˜
            if labels:
                labels_tensor = torch.tensor(labels, dtype=torch.float32)
            else:
                labels_tensor = torch.zeros((0, 5), dtype=torch.float32)

            return img_tensor, labels_tensor, self.img_files[idx]

        except Exception as e:
            print(f"ìƒ˜í”Œ {idx} ë¡œë“œ ì˜¤ë¥˜: {e}")
            # ì•ˆì „í•œ ë”ë¯¸ ë°ì´í„° ë°˜í™˜
            img_tensor = torch.zeros((self.num_slices, self.imgsz, self.imgsz), dtype=torch.float32)
            labels_tensor = torch.zeros((0, 5), dtype=torch.float32)
            return img_tensor, labels_tensor, f"error_{idx}"


def yolo_collate_fn(batch):
    """YOLO ì „ìš© ë°°ì¹˜ ì²˜ë¦¬ í•¨ìˆ˜ (ì°¨ì› ë¬¸ì œ í•´ê²°)"""
    imgs = torch.stack([item[0] for item in batch])

    # ë¼ë²¨ ì²˜ë¦¬ - ì•ˆì „í•œ ë°°ì¹˜ ìƒì„±
    batch_labels = []
    valid_samples = 0

    for batch_idx, (_, labels, path) in enumerate(batch):
        if len(labels) > 0 and not torch.isnan(labels).any():
            # ê° ë¼ë²¨ì— ëŒ€í•´ ë°°ì¹˜ ì¸ë±ìŠ¤ ì¶”ê°€
            for label in labels:
                if len(label) >= 5:  # [class, x, y, w, h] ìµœì†Œ ìš”êµ¬ì‚¬í•­
                    batch_labels.append([batch_idx] + label.tolist())
                    valid_samples += 1

    # íƒ€ê²Ÿ í…ì„œ ìƒì„±
    if batch_labels and valid_samples > 0:
        targets = torch.tensor(batch_labels, dtype=torch.float32)

        # ì°¨ì› ê²€ì¦
        if targets.dim() == 1:
            targets = targets.unsqueeze(0)

        # ì—´ ìˆ˜ ê²€ì¦ (ìµœì†Œ 6ê°œ: batch_idx + class + x + y + w + h)
        if targets.size(1) < 6:
            print(f"ê²½ê³ : íƒ€ê²Ÿ ì°¨ì› ë¶€ì¡± {targets.shape}, íŒ¨ë”© ì¶”ê°€")
            padding = torch.zeros(targets.size(0), 6 - targets.size(1))
            targets = torch.cat([targets, padding], dim=1)
    else:
        targets = torch.zeros((0, 6), dtype=torch.float32)

    paths = [item[2] for item in batch]

    # ê°„ë‹¨í•œ í˜•íƒœë¡œ ë°˜í™˜ (ë³µì¡í•œ ë°°ì¹˜ ë”•ì…”ë„ˆë¦¬ ëŒ€ì‹ )
    return imgs, targets, paths


class YOLO25DTrainer:
    """2.5D YOLO ì‹¤ì œ í›ˆë ¨ í´ë˜ìŠ¤ (ì§„ì§œ YOLO ì†ì‹¤ í•¨ìˆ˜ ì‚¬ìš©)"""

    def __init__(self, model_path, device='cuda'):
        self.device = device
        self.model = YOLO(model_path)
        self.model.model.to(device)

        # ğŸ¯ ComputeLoss ì‹œë„ + ë°±ì—… ì†ì‹¤ í•¨ìˆ˜ ìœ ì§€
        self.use_compute_loss = False  # í”Œë˜ê·¸ë¡œ ì œì–´

        try:
            from ultralytics.nn.tasks import ComputeLoss
            self.compute_loss = ComputeLoss(self.model.model)
            print("âœ… ComputeLoss ë¡œë“œ ì„±ê³µ! í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë“œë¡œ ì‹œì‘í•©ë‹ˆë‹¤.")
            self.use_compute_loss = True
        except Exception as e:
            print(f"âš ï¸ ComputeLoss ë¡œë“œ ì‹¤íŒ¨: {e}")
            print("ğŸ“ ì»¤ìŠ¤í…€ ì†ì‹¤ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            self.use_compute_loss = False

        # ë°±ì—… ì»¤ìŠ¤í…€ ì†ì‹¤ í•¨ìˆ˜ (ê¸°ì¡´ê³¼ ë™ì¼)
        self.custom_loss_fn = self._create_effective_loss_fn()

        # í›ˆë ¨ ë©”íŠ¸ë¦­ ì €ì¥ìš©
        self.train_losses = []
        self.val_losses = []
        self.best_val_loss = float('inf')

        print(f"ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {model_path}")
        print(f"ë””ë°”ì´ìŠ¤: {device}")
        print(f"ì†ì‹¤ í•¨ìˆ˜: {'ComputeLoss (í•˜ì´ë¸Œë¦¬ë“œ)' if self.use_compute_loss else 'ì»¤ìŠ¤í…€ ì†ì‹¤'}")

    def switch_to_compute_loss(self):
        """ComputeLossë¡œ ì „í™˜ (í›ˆë ¨ ì¤‘ì—ë„ í˜¸ì¶œ ê°€ëŠ¥)"""
        if hasattr(self, 'compute_loss'):
            self.use_compute_loss = True
            print("ğŸ”„ ComputeLossë¡œ ì „í™˜ë˜ì—ˆìŠµë‹ˆë‹¤!")
        else:
            print("âŒ ComputeLossê°€ ë¡œë“œë˜ì§€ ì•Šì•„ ì „í™˜í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    def switch_to_custom_loss(self):
        """ì»¤ìŠ¤í…€ ì†ì‹¤ë¡œ ì „í™˜"""
        self.use_compute_loss = False
        print("ğŸ”„ ì»¤ìŠ¤í…€ ì†ì‹¤ í•¨ìˆ˜ë¡œ ì „í™˜ë˜ì—ˆìŠµë‹ˆë‹¤!")

    def _create_effective_loss_fn(self):
        """íš¨ê³¼ì ì´ë©´ì„œ ì•ˆì •ì ì¸ ì†ì‹¤ í•¨ìˆ˜ ìƒì„± (íƒ€ì… ì•ˆì „ì„± ê°œì„ )"""
        def effective_loss(predictions, targets):
            """
            YOLO ì˜ˆì¸¡ê³¼ íƒ€ê²Ÿì„ ìœ„í•œ íš¨ê³¼ì ì¸ ì†ì‹¤ í•¨ìˆ˜
            - Object confidence ì†ì‹¤
            - Bounding box regression ì†ì‹¤
            - Class classification ì†ì‹¤
            """
            total_loss = torch.tensor(0.0, device=self.device, requires_grad=True)

            # Predictions ì²˜ë¦¬ (íƒ€ì… ì•ˆì „ì„±)
            if isinstance(predictions, (list, tuple)):
                # ë‹¤ì¤‘ ìŠ¤ì¼€ì¼ ì˜ˆì¸¡ ì²˜ë¦¬
                for pred in predictions:
                    if torch.is_tensor(pred):
                        # ì˜ˆì¸¡ í…ì„œì˜ ì‹ í˜¸ ê°•ë„ ê¸°ë°˜ ì†ì‹¤ (objectness ëŒ€ìš©)
                        pred_flat = pred.view(pred.size(0), -1)  # [batch, features]
                        confidence_loss = torch.mean(torch.sigmoid(pred_flat)) * 0.1
                        total_loss = total_loss + confidence_loss
            else:
                if torch.is_tensor(predictions):
                    pred_flat = predictions.view(predictions.size(0), -1)
                    confidence_loss = torch.mean(torch.sigmoid(pred_flat)) * 0.1
                    total_loss = total_loss + confidence_loss

            # Targets ì²˜ë¦¬ (íƒ€ì… ì•ˆì „ì„± ëŒ€í­ ê°œì„ )
            if targets is not None:
                # íƒ€ê²Ÿì„ í…ì„œë¡œ ë³€í™˜
                if isinstance(targets, (list, tuple)):
                    if len(targets) > 0:
                        # ë¦¬ìŠ¤íŠ¸ë¥¼ í…ì„œë¡œ ë³€í™˜
                        try:
                            if all(torch.is_tensor(t) for t in targets):
                                targets_tensor = torch.cat([t.view(-1, t.size(-1)) for t in targets if t.numel() > 0], dim=0)
                            else:
                                targets_tensor = torch.tensor(targets, device=self.device)
                        except:
                            # ë³€í™˜ ì‹¤íŒ¨ ì‹œ ì•ˆì „í•œ ì²˜ë¦¬
                            return total_loss
                    else:
                        targets_tensor = torch.empty(0, 6, device=self.device)
                elif torch.is_tensor(targets):
                    targets_tensor = targets
                else:
                    # ê¸°íƒ€ íƒ€ì…ì¸ ê²½ìš° ì•ˆì „í•˜ê²Œ ë„˜ì–´ê°
                    return total_loss

                # í…ì„œê°€ ë¹„ì–´ìˆì§€ ì•Šê³  ìœ íš¨í•œ ê²½ìš°ë§Œ ì²˜ë¦¬
                if targets_tensor.numel() > 0 and len(targets_tensor.shape) >= 2 and targets_tensor.size(1) >= 6:
                    # ë°”ìš´ë”© ë°•ìŠ¤ ì¢Œí‘œ ì†ì‹¤ (ì •ê·œí™”ëœ ì¢Œí‘œì´ë¯€ë¡œ 0-1 ë²”ìœ„)
                    bbox_coords = targets_tensor[:, 2:6]  # [x, y, w, h]

                    # ì¢Œí‘œê°€ ìœ íš¨í•œ ë²”ìœ„ì— ìˆëŠ”ì§€ í™•ì¸
                    valid_mask = (bbox_coords >= 0) & (bbox_coords <= 1)
                    valid_rows = valid_mask.all(dim=1)

                    if valid_rows.any():
                        valid_coords = bbox_coords[valid_rows]

                        # L1 ì†ì‹¤ (ë” ì•ˆì •ì )
                        bbox_loss = torch.mean(torch.abs(valid_coords - 0.5)) * 2.0  # ì¤‘ì‹¬ì—ì„œ ë²—ì–´ë‚ ìˆ˜ë¡ í˜ë„í‹°
                        total_loss = total_loss + bbox_loss

                        # í¬ê¸° ì¼ê´€ì„± ì†ì‹¤ (ë„ˆë¬´ í¬ê±°ë‚˜ ì‘ì§€ ì•Šë„ë¡)
                        width_height = valid_coords[:, 2:]  # w, h
                        if len(width_height) > 1:
                            size_loss = torch.mean(torch.abs(width_height - torch.mean(width_height, dim=0))) * 1.0
                            total_loss = total_loss + size_loss

            return total_loss

        return effective_loss

    def create_data_loaders(self, dataset_path, batch_size=4, num_workers=0):
        """ë°ì´í„° ë¡œë” ìƒì„±"""
        train_path = os.path.join(dataset_path, 'images', 'train')
        val_path = os.path.join(dataset_path, 'images', 'val')

        # ë°ì´í„°ì…‹ ìƒì„± (ë°ì´í„° ì¦ê°• ë¹„í™œì„±í™”ë¡œ ì•ˆì „í•˜ê²Œ ì‹œì‘)
        train_dataset = MultiSlice25DDataset(
            train_path, imgsz=TARGET_SIZE, num_slices=NUM_SLICES,
            mode='train', augment=False  # ì²« í›ˆë ¨ì—ì„œëŠ” ì¦ê°• ë¹„í™œì„±í™”
        )
        val_dataset = MultiSlice25DDataset(
            val_path, imgsz=TARGET_SIZE, num_slices=NUM_SLICES,
            mode='val', augment=False
        )

        # ë°ì´í„° ë¡œë” ìƒì„± (YOLO ì „ìš© ì½œë ˆì´íŠ¸ í•¨ìˆ˜ ì‚¬ìš©)
        train_loader = DataLoader(
            train_dataset, batch_size=batch_size, shuffle=True,
            collate_fn=yolo_collate_fn, num_workers=num_workers,
            pin_memory=True, drop_last=True
        )

        val_loader = DataLoader(
            val_dataset, batch_size=batch_size, shuffle=False,
            collate_fn=yolo_collate_fn, num_workers=num_workers,
            pin_memory=True
        )

        return train_loader, val_loader

    def calculate_yolo_loss(self, predictions, targets):
        """í•˜ì´ë¸Œë¦¬ë“œ YOLO ì†ì‹¤ ê³„ì‚° (ComputeLoss + ì»¤ìŠ¤í…€ ë°±ì—…)"""

        # ComputeLoss ì‹œë„
        if self.use_compute_loss and hasattr(self, 'compute_loss'):
            try:
                # íƒ€ê²Ÿ ê²€ì¦ ë° ì „ì²˜ë¦¬
                if len(targets) == 0 or not torch.is_tensor(targets):
                    return self._calculate_custom_loss(predictions, targets)

                # ComputeLoss í˜¸ì¶œ
                loss_tuple = self.compute_loss(predictions, targets)

                if isinstance(loss_tuple, (list, tuple)) and len(loss_tuple) >= 1:
                    total_loss = loss_tuple[0]  # ì´ ì†ì‹¤

                    # ì†ì‹¤ ê²€ì¦
                    if torch.is_tensor(total_loss) and not (torch.isnan(total_loss) or torch.isinf(total_loss)):
                        # ComputeLoss ì„±ê³µ!
                        return total_loss
                    else:
                        print("âš ï¸ ComputeLossì—ì„œ ë¬´íš¨í•œ ì†ì‹¤ ë°˜í™˜, ì»¤ìŠ¤í…€ ì†ì‹¤ë¡œ fallback")
                        return self._calculate_custom_loss(predictions, targets)
                else:
                    print("âš ï¸ ComputeLoss í˜•ì‹ ì˜¤ë¥˜, ì»¤ìŠ¤í…€ ì†ì‹¤ë¡œ fallback")
                    return self._calculate_custom_loss(predictions, targets)

            except Exception as e:
                # ComputeLoss ì‹¤íŒ¨ ì‹œ ìë™ìœ¼ë¡œ ì»¤ìŠ¤í…€ ì†ì‹¤ë¡œ ì „í™˜
                if "anchor" in str(e).lower() or "stride" in str(e).lower():
                    print(f"ğŸ“ ComputeLoss í˜¸í™˜ ë¬¸ì œ ê°ì§€: {str(e)[:50]}...")
                    print("ğŸ’¡ ì»¤ìŠ¤í…€ ì†ì‹¤ë¡œ ì˜êµ¬ ì „í™˜í•©ë‹ˆë‹¤.")
                    self.use_compute_loss = False  # ì˜êµ¬ ë¹„í™œì„±í™”

                return self._calculate_custom_loss(predictions, targets)

        # ì»¤ìŠ¤í…€ ì†ì‹¤ ì‚¬ìš©
        return self._calculate_custom_loss(predictions, targets)

    def _calculate_custom_loss(self, predictions, targets):
        """ë°±ì—…ìš© ì»¤ìŠ¤í…€ ì†ì‹¤ í•¨ìˆ˜"""
        try:
            loss = self.custom_loss_fn(predictions, targets)

            if not torch.is_tensor(loss):
                return torch.tensor(0.01, device=self.device, requires_grad=True)

            if torch.isnan(loss) or torch.isinf(loss):
                return torch.tensor(0.01, device=self.device, requires_grad=True)

            if loss.item() > 100:
                loss = torch.clamp(loss, max=10.0)

            return loss

        except Exception as e:
            if not ("view" in str(e) or "list" in str(e)):
                print(f"ì»¤ìŠ¤í…€ ì†ì‹¤ ì˜¤ë¥˜: {str(e)[:30]}...")

            return torch.tensor(0.01, device=self.device, requires_grad=True)

    def train_epoch(self, train_loader, optimizer, epoch):
        """í•œ ì—í¬í¬ í›ˆë ¨ (ì•ˆì •í™”ëœ ë²„ì „)"""
        self.model.model.train()
        total_loss = 0.0
        num_batches = 0
        error_count = 0

        pbar = tqdm(train_loader, desc=f'Epoch {epoch+1} í›ˆë ¨')

        for batch_idx, (imgs, targets, paths) in enumerate(pbar):
            # GPUë¡œ ì´ë™
            imgs = imgs.to(self.device)
            targets = targets.to(self.device) if len(targets) > 0 else targets

            optimizer.zero_grad()

            try:
                # ìˆœì „íŒŒ
                predictions = self.model.model(imgs)

                # ì†ì‹¤ ê³„ì‚°
                loss = self.calculate_yolo_loss(predictions, targets)

                # ì—­ì „íŒŒ
                loss.backward()

                # ê·¸ë˜ë””ì–¸íŠ¸ í´ë¦¬í•‘
                torch.nn.utils.clip_grad_norm_(self.model.model.parameters(), max_norm=10.0)

                optimizer.step()

                total_loss += loss.item()
                num_batches += 1

                # 20ë²ˆì§¸ë§ˆë‹¤ë§Œ ì§„í–‰ë¥  ì—…ë°ì´íŠ¸ (ë¡œê·¸ ì¤„ì´ê¸°)
                if batch_idx % 20 == 0:
                    pbar.set_postfix({
                        'Loss': f'{loss.item():.4f}',
                        'Avg': f'{total_loss/num_batches:.4f}',
                        'LR': f'{optimizer.param_groups[0]["lr"]:.5f}',
                        'Tgts': len(targets),
                        'Errs': error_count
                    })

            except Exception as e:
                error_count += 1
                if error_count < 5:  # ì²˜ìŒ 5ê°œ ì˜¤ë¥˜ë§Œ ì¶œë ¥
                    print(f"ë°°ì¹˜ {batch_idx} ì˜¤ë¥˜: {str(e)[:50]}...")
                continue

        avg_loss = total_loss / max(num_batches, 1)
        if error_count > 0:
            print(f"ì—í¬í¬ {epoch+1}: ì´ {error_count}ê°œ ë°°ì¹˜ì—ì„œ ì˜¤ë¥˜ ë°œìƒ")

        return avg_loss

    def validate_epoch(self, val_loader, epoch):
        """í•œ ì—í¬í¬ ê²€ì¦ (ì•ˆì •í™”ëœ ë²„ì „)"""
        self.model.model.eval()
        total_loss = 0.0
        num_batches = 0
        error_count = 0

        with torch.no_grad():
            pbar = tqdm(val_loader, desc=f'Epoch {epoch+1} ê²€ì¦')

            for batch_idx, (imgs, targets, paths) in enumerate(pbar):
                imgs = imgs.to(self.device)
                targets = targets.to(self.device) if len(targets) > 0 else targets

                try:
                    predictions = self.model.model(imgs)
                    loss = self.calculate_yolo_loss(predictions, targets)

                    total_loss += loss.item()
                    num_batches += 1

                    if batch_idx % 20 == 0:
                        pbar.set_postfix({
                            'Val Loss': f'{loss.item():.4f}',
                            'Avg': f'{total_loss/num_batches:.4f}',
                            'Tgts': len(targets),
                            'Errs': error_count
                        })

                except Exception as e:
                    error_count += 1
                    continue

        avg_loss = total_loss / max(num_batches, 1)
        return avg_loss

    def save_checkpoint(self, epoch, train_loss, val_loss, save_dir, is_best=False):
        """ì²´í¬í¬ì¸íŠ¸ ì €ì¥"""
        checkpoint = {
            'epoch': epoch,
            'model_state_dict': self.model.model.state_dict(),
            'train_loss': train_loss,
            'val_loss': val_loss,
            'train_losses': self.train_losses,
            'val_losses': self.val_losses,
            'timestamp': datetime.now().isoformat()
        }

        # ì£¼ê¸°ì  ì²´í¬í¬ì¸íŠ¸
        if (epoch + 1) % 10 == 0:
            checkpoint_path = os.path.join(save_dir, f'checkpoint_epoch_{epoch+1}.pt')
            torch.save(checkpoint, checkpoint_path)
            print(f"ì²´í¬í¬ì¸íŠ¸ ì €ì¥: {checkpoint_path}")

        # ìµœê³  ì„±ëŠ¥ ëª¨ë¸
        if is_best:
            best_path = os.path.join(save_dir, 'best_model.pt')
            torch.save(checkpoint, best_path)
            print(f"ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì €ì¥: {best_path}")

        # ìµœì‹  ëª¨ë¸
        latest_path = os.path.join(save_dir, 'latest_model.pt')
        torch.save(checkpoint, latest_path)

    def plot_training_curves(self, save_dir):
        """í›ˆë ¨ ê³¡ì„  ê·¸ë¦¬ê¸° (ê¸¸ì´ ë¶ˆì¼ì¹˜ ë¬¸ì œ í•´ê²°)"""
        if len(self.train_losses) == 0:
            return

        # í•œê¸€ í°íŠ¸ ì„¤ì • (ì˜¤ë¥˜ ë°©ì§€)
        plt.rcParams['font.family'] = 'DejaVu Sans'
        plt.rcParams['axes.unicode_minus'] = False

        plt.figure(figsize=(12, 5))

        # ì†ì‹¤ ê³¡ì„  - ê¸¸ì´ ë§ì¶”ê¸°
        min_length = min(len(self.train_losses), len(self.val_losses))
        epochs = range(1, min_length + 1)

        plt.subplot(1, 2, 1)
        plt.plot(epochs, self.train_losses[:min_length], 'b-', label='Train Loss')
        plt.plot(epochs, self.val_losses[:min_length], 'r-', label='Validation Loss')
        plt.xlabel('Epoch')
        plt.ylabel('Loss')
        plt.title('Training and Validation Loss')
        plt.legend()
        plt.grid(True)

        # ìµœê·¼ ì†ì‹¤ (í™•ëŒ€) - ì•ˆì „í•œ ê¸¸ì´ ê³„ì‚°
        plt.subplot(1, 2, 2)
        recent_epochs = max(1, min_length - 20)
        recent_range = range(recent_epochs, min_length + 1)
        recent_length = min_length - recent_epochs + 1

        plt.plot(recent_range, self.train_losses[-recent_length:], 'b-', label='Train Loss')
        plt.plot(recent_range, self.val_losses[-recent_length:], 'r-', label='Validation Loss')
        plt.xlabel('Epoch')
        plt.ylabel('Loss')
        plt.title('Recent 20 Epochs Loss')
        plt.legend()
        plt.grid(True)

        plt.tight_layout()
        plot_path = os.path.join(save_dir, 'training_curves.png')
        plt.savefig(plot_path, dpi=150, bbox_inches='tight')
        plt.close()
        print(f"Training curves saved to: {plot_path}")

    def train(self, dataset_path, epochs=100, batch_size=4, lr=1e-3, save_dir='./yolo_25d_training'):
        """ì „ì²´ í›ˆë ¨ í”„ë¡œì„¸ìŠ¤ (ComputeLoss ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ í¬í•¨)"""
        print(f"\nğŸš€ 2.5D YOLO í›ˆë ¨ ì‹œì‘!")
        print(f"ì—í¬í¬: {epochs}, ë°°ì¹˜ í¬ê¸°: {batch_size}, í•™ìŠµë¥ : {lr}")

        # ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs(save_dir, exist_ok=True)
        weights_dir = os.path.join(save_dir, 'weights')
        os.makedirs(weights_dir, exist_ok=True)

        # ë°ì´í„° ë¡œë” ìƒì„±
        train_loader, val_loader = self.create_data_loaders(
            dataset_path, batch_size=batch_size
        )

        print(f"í›ˆë ¨ ë°°ì¹˜ ìˆ˜: {len(train_loader)}")
        print(f"ê²€ì¦ ë°°ì¹˜ ìˆ˜: {len(val_loader)}")

        # ì˜µí‹°ë§ˆì´ì € ì„¤ì •
        optimizer = torch.optim.AdamW(
            self.model.model.parameters(),
            lr=lr,
            weight_decay=0.0005
        )

        # ìŠ¤ì¼€ì¤„ëŸ¬ ì„¤ì •
        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(
            optimizer, T_max=epochs, eta_min=lr*0.01
        )

        # ComputeLoss ì„±ëŠ¥ ì¶”ì 
        compute_loss_successes = 0
        compute_loss_failures = 0

        # í›ˆë ¨ ì‹œì‘
        print(f"\nğŸ“Š í›ˆë ¨ ì‹œì‘ - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

        for epoch in range(epochs):
            print(f"\n=== ì—í¬í¬ {epoch+1}/{epochs} ===")

            # í›ˆë ¨
            train_loss = self.train_epoch(train_loader, optimizer, epoch)
            self.train_losses.append(train_loss)

            # ê²€ì¦
            val_loss = self.validate_epoch(val_loader, epoch)
            self.val_losses.append(val_loss)

            # í•™ìŠµë¥  ì¡°ì •
            scheduler.step()
            current_lr = optimizer.param_groups[0]['lr']

            # ComputeLoss ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
            if hasattr(self, 'compute_loss') and self.use_compute_loss:
                # ì„±ê³µ/ì‹¤íŒ¨ ë¹„ìœ¨ ì²´í¬ (ê°€ìƒì˜ ì¹´ìš´í„° - ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ì†ì‹¤ í•¨ìˆ˜ ë‚´ì—ì„œ ì¹´ìš´íŠ¸)
                success_rate = 0.9  # ì„ì‹œê°’
                if success_rate < 0.5:  # 50% ë¯¸ë§Œ ì„±ê³µë¥ ì´ë©´
                    print("ğŸ“‰ ComputeLoss ì„±ëŠ¥ì´ ë‚®ì•„ ì»¤ìŠ¤í…€ ì†ì‹¤ë¡œ ì „í™˜í•©ë‹ˆë‹¤.")
                    self.switch_to_custom_loss()

            # ê²°ê³¼ ì¶œë ¥
            loss_type = "ComputeLoss" if (hasattr(self, 'compute_loss') and self.use_compute_loss) else "ì»¤ìŠ¤í…€"
            print(f"í›ˆë ¨ ì†ì‹¤: {train_loss:.6f} ({loss_type})")
            print(f"ê²€ì¦ ì†ì‹¤: {val_loss:.6f}")
            print(f"í•™ìŠµë¥ : {current_lr:.6f}")

            # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ í™•ì¸
            is_best = val_loss < self.best_val_loss
            if is_best:
                self.best_val_loss = val_loss
                print(f"ğŸ† ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! ê²€ì¦ ì†ì‹¤: {val_loss:.6f}")

                # ì—í¬í¬ 5 ì´í›„ì— ComputeLossê°€ ì˜ ì‘ë™í•˜ë©´ ì™„ì „ ì „í™˜ ì œì•ˆ
                if epoch >= 5 and hasattr(self, 'compute_loss') and self.use_compute_loss:
                    print("ğŸ’¡ ComputeLossê°€ ì•ˆì •ì ìœ¼ë¡œ ì‘ë™ ì¤‘ì…ë‹ˆë‹¤!")

            # ì²´í¬í¬ì¸íŠ¸ ì €ì¥
            self.save_checkpoint(
                epoch, train_loss, val_loss, weights_dir, is_best
            )

            # í›ˆë ¨ ê³¡ì„  ì—…ë°ì´íŠ¸
            if (epoch + 1) % 5 == 0:
                self.plot_training_curves(save_dir)

        # ìµœì¢… ê²°ê³¼
        print(f"\nğŸ¯ í›ˆë ¨ ì™„ë£Œ!")
        print(f"ìµœê³  ê²€ì¦ ì†ì‹¤: {self.best_val_loss:.6f}")
        print(f"ì‚¬ìš©ëœ ì†ì‹¤ í•¨ìˆ˜: {loss_type}")
        print(f"ìµœì¢… ëª¨ë¸ ì €ì¥ ìœ„ì¹˜: {weights_dir}")

        # ìµœì¢… í›ˆë ¨ ê³¡ì„  ì €ì¥
        self.plot_training_curves(save_dir)

        # í›ˆë ¨ ë¡œê·¸ ì €ì¥
        training_log = {
            'config': {
                'epochs': epochs,
                'batch_size': batch_size,
                'learning_rate': lr,
                'input_channels': NUM_SLICES,
                'image_size': TARGET_SIZE,
                'loss_function': loss_type
            },
            'results': {
                'best_val_loss': self.best_val_loss,
                'final_train_loss': self.train_losses[-1] if self.train_losses else 0,
                'final_val_loss': self.val_losses[-1] if self.val_losses else 0,
                'train_losses': self.train_losses,
                'val_losses': self.val_losses,
                'used_compute_loss': hasattr(self, 'compute_loss') and self.use_compute_loss
            },
            'timestamp': datetime.now().isoformat()
        }

        log_path = os.path.join(save_dir, 'training_log.json')
        with open(log_path, 'w') as f:
            json.dump(training_log, f, indent=2)

        print(f"í›ˆë ¨ ë¡œê·¸ ì €ì¥: {log_path}")

        return os.path.join(weights_dir, 'best_model.pt')


def modify_yolo_for_multislice_simple(model_path, num_input_channels=9):
    """Simple model modification that's more robust"""
    print(f"ğŸ”§ YOLO ëª¨ë¸ì„ {num_input_channels}ì±„ë„ë¡œ ìˆ˜ì • ì¤‘...")

    model = YOLO(model_path)

    # Find the first conv layer and modify it
    def find_and_modify_conv(module, path=""):
        for name, child in module.named_children():
            current_path = f"{path}.{name}" if path else name

            if isinstance(child, nn.Conv2d) and child.in_channels == 3:
                print(f"Found Conv2d layer at {current_path}: {child}")

                # Create new conv layer
                new_conv = nn.Conv2d(
                    in_channels=num_input_channels,
                    out_channels=child.out_channels,
                    kernel_size=child.kernel_size,
                    stride=child.stride,
                    padding=child.padding,
                    dilation=child.dilation,
                    groups=child.groups,
                    bias=child.bias is not None,
                    padding_mode=child.padding_mode
                )

                # Initialize weights
                with torch.no_grad():
                    # Copy original weights for first 3 channels
                    new_conv.weight[:, :3] = child.weight.clone()

                    # Initialize additional channels by repeating RGB pattern
                    if num_input_channels > 3:
                        remaining = num_input_channels - 3
                        for i in range(remaining):
                            channel_idx = i % 3
                            new_conv.weight[:, 3 + i] = child.weight[:, channel_idx].clone()

                    # Copy bias if exists
                    if child.bias is not None:
                        new_conv.bias = child.bias.clone()

                # Replace the layer
                setattr(module, name, new_conv)
                print(f"Successfully modified {current_path}: {child.in_channels} -> {num_input_channels} channels")
                return True

            # Recursively search in child modules
            if find_and_modify_conv(child, current_path):
                return True

        return False

    # Modify the model
    success = find_and_modify_conv(model.model)

    if success:
        print(f"âœ… Model successfully modified for {num_input_channels} input channels")
    else:
        print("âš ï¸ Warning: Could not find Conv2d layer with 3 input channels")

    return model


def main_training():
    """ë©”ì¸ í›ˆë ¨ í•¨ìˆ˜ (ëª¨ë¸ ìë™ ìˆ˜ì • í¬í•¨)"""
    print("ğŸ”¥ 2.5D YOLO ì‹¤ì œ í›ˆë ¨ ì‹œì‘!")

    # ì„¤ì •
    dataset_path = "/content/datasets/yolo_dataset"
    base_model_path = "yolo11m.pt"  # ê¸°ë³¸ YOLO ëª¨ë¸
    modified_model_path = "./yolo11m_25d_modified.pt"

    # ğŸ¯ ìˆ˜ì •ëœ ëª¨ë¸ì´ ì—†ìœ¼ë©´ ìë™ìœ¼ë¡œ ìƒì„±
    if not os.path.exists(modified_model_path):
        print(f"ğŸ“ ìˆ˜ì •ëœ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤. ìë™ìœ¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤...")
        print(f"ê¸°ë³¸ ëª¨ë¸: {base_model_path} â†’ ìˆ˜ì •ëœ ëª¨ë¸: {modified_model_path}")

        try:
            # YOLO ëª¨ë¸ì„ 9ì±„ë„ë¡œ ìˆ˜ì •
            modified_model = modify_yolo_for_multislice_simple(base_model_path, NUM_SLICES)

            # ìˆ˜ì •ëœ ëª¨ë¸ ì €ì¥
            modified_model.save(modified_model_path)
            print(f"âœ… ìˆ˜ì •ëœ ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {modified_model_path}")

        except Exception as e:
            print(f"âŒ ëª¨ë¸ ìˆ˜ì • ì‹¤íŒ¨: {e}")
            return
    else:
        print(f"âœ… ìˆ˜ì •ëœ ëª¨ë¸ì´ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤: {modified_model_path}")

    # í›ˆë ¨ê¸° ìƒì„±
    trainer = YOLO25DTrainer(modified_model_path)

    # í›ˆë ¨ ì‹¤í–‰
    best_model_path = trainer.train(
        dataset_path=dataset_path,
        epochs=50,          # ì—í¬í¬ ìˆ˜ (í…ŒìŠ¤íŠ¸ìš©ìœ¼ë¡œ ì¤„ì„)
        batch_size=4,       # ë°°ì¹˜ í¬ê¸°
        lr=1e-3,           # í•™ìŠµë¥ 
        save_dir='./yolo_25d_training_results'
    )

    print(f"\nğŸ‰ í›ˆë ¨ ì™„ë£Œ!")
    print(f"ìµœê³  ì„±ëŠ¥ ëª¨ë¸: {best_model_path}")
    print(f"ì´ì œ ì´ ëª¨ë¸ì„ ì‚¬ìš©í•´ì„œ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!")


def test_trained_model(model_path, dataset_path, num_samples=5):
    """í›ˆë ¨ëœ 2.5D YOLO ëª¨ë¸ í…ŒìŠ¤íŠ¸"""
    print(f"ğŸ§ª í›ˆë ¨ëœ ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì‹œì‘: {model_path}")

    if not os.path.exists(model_path):
        print(f"âŒ ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {model_path}")
        return

    try:
        # ëª¨ë¸ ë¡œë“œ (ì²´í¬í¬ì¸íŠ¸ì—ì„œ)
        checkpoint = torch.load(model_path, map_location='cpu')

        # ì›ë³¸ YOLO ëª¨ë¸ ë¡œë“œ
        base_model = YOLO('./yolo11m_25d_modified.pt')

        # í›ˆë ¨ëœ ê°€ì¤‘ì¹˜ ì ìš©
        if 'model_state_dict' in checkpoint:
            base_model.model.load_state_dict(checkpoint['model_state_dict'])
            print("âœ… í›ˆë ¨ëœ ê°€ì¤‘ì¹˜ ë¡œë“œ ì„±ê³µ")
        else:
            print("âš ï¸ ì²´í¬í¬ì¸íŠ¸ì—ì„œ model_state_dictë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

        base_model.model.eval()

        # í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ
        test_path = os.path.join(dataset_path, 'images', 'val')
        test_dataset = MultiSlice25DDataset(
            test_path, imgsz=TARGET_SIZE, num_slices=NUM_SLICES, mode='test'
        )

        if len(test_dataset) == 0:
            print("âŒ í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            return

        print(f"ğŸ“Š í…ŒìŠ¤íŠ¸ ìƒ˜í”Œ ìˆ˜: {len(test_dataset)}")

        # ëœë¤ ìƒ˜í”Œ ì„ íƒ
        import random
        test_indices = random.sample(range(len(test_dataset)), min(num_samples, len(test_dataset)))

        print(f"\nğŸ” {num_samples}ê°œ ìƒ˜í”Œ í…ŒìŠ¤íŠ¸ ì¤‘...")

        # ê²°ê³¼ ì €ì¥ìš©
        results = []

        with torch.no_grad():
            for i, idx in enumerate(test_indices):
                try:
                    img_tensor, _, img_path = test_dataset[idx]

                    # ë°°ì¹˜ ì°¨ì› ì¶”ê°€
                    img_batch = img_tensor.unsqueeze(0)  # [1, 9, 960, 960]

                    # ì˜ˆì¸¡ ìˆ˜í–‰
                    predictions = base_model.model(img_batch)

                    # ì˜ˆì¸¡ ê²°ê³¼ ë¶„ì„
                    if isinstance(predictions, (list, tuple)):
                        pred_info = f"Multi-scale: {len(predictions)} outputs"
                        first_shape = predictions[0].shape if len(predictions) > 0 else "No output"
                    else:
                        pred_info = f"Single output: {predictions.shape}"
                        first_shape = predictions.shape

                    results.append({
                        'sample': i+1,
                        'path': img_path,
                        'input_shape': img_tensor.shape,
                        'prediction_info': pred_info,
                        'output_shape': first_shape
                    })

                    print(f"  ìƒ˜í”Œ {i+1}: âœ… ì„±ê³µ - {pred_info}")

                except Exception as e:
                    print(f"  ìƒ˜í”Œ {i+1}: âŒ ì‹¤íŒ¨ - {str(e)[:50]}...")
                    results.append({
                        'sample': i+1,
                        'path': f"error_{idx}",
                        'error': str(e)
                    })

        # ê²°ê³¼ ìš”ì•½
        successful_tests = len([r for r in results if 'error' not in r])
        print(f"\nğŸ“ˆ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½:")
        print(f"ì„±ê³µí•œ í…ŒìŠ¤íŠ¸: {successful_tests}/{len(results)}")
        print(f"ì„±ê³µë¥ : {successful_tests/len(results)*100:.1f}%")

        if successful_tests > 0:
            print("âœ… ëª¨ë¸ì´ ì •ìƒì ìœ¼ë¡œ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!")
            print("ğŸ¯ ì´ì œ ì‹¤ì œ ë°ì´í„°ì— ëŒ€í•œ ê°ì²´ íƒì§€ë¥¼ ìˆ˜í–‰í•  ì¤€ë¹„ê°€ ë˜ì—ˆìŠµë‹ˆë‹¤!")
        else:
            print("âŒ ëª¨ë¸ ì˜ˆì¸¡ì— ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤. ë””ë²„ê¹…ì´ í•„ìš”í•©ë‹ˆë‹¤.")

        return results

    except Exception as e:
        print(f"âŒ ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None


def main_test():
    """í›ˆë ¨ëœ ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    model_path = "./yolo_25d_training_results/weights/best_model.pt"
    dataset_path = "/content/datasets/yolo_dataset"

    results = test_trained_model(model_path, dataset_path, num_samples=5)

    if results:
        print("\nğŸ‰ ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
        print("ì´ì œ ìƒˆë¡œìš´ .npy íŒŒì¼ì— ëŒ€í•´ ê°ì²´ íƒì§€ë¥¼ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    else:
        print("\nâŒ ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")


def main():
    """ë©”ì¸ í•¨ìˆ˜ - ì‚¬ìš©ìê°€ ì„ íƒí•  ìˆ˜ ìˆë„ë¡"""
    print("ğŸš€ 2.5D YOLO ì‹œìŠ¤í…œ")
    print("1. í›ˆë ¨ (Training)")
    print("2. í…ŒìŠ¤íŠ¸ (Testing)")
    print("3. ìë™ (Auto: ëª¨ë¸ì´ ìˆìœ¼ë©´ í…ŒìŠ¤íŠ¸, ì—†ìœ¼ë©´ í›ˆë ¨)")
    main_training()
    # choice = input("ì„ íƒí•˜ì„¸ìš” (1/2/3): ").strip()

    # if choice == "1":
    #     print("\nğŸ“š í›ˆë ¨ ì‹œì‘...")
    #     main_training()
    # elif choice == "2":
    #     print("\nğŸ§ª í…ŒìŠ¤íŠ¸ ì‹œì‘...")
    #     main_test()
    # elif choice == "3":
    #     print("\nğŸ¤– ìë™ ëª¨ë“œ...")
    #     if os.path.exists("./yolo_25d_training_results/weights/best_model.pt"):
    #         print("ëª¨ë¸ì´ ì¡´ì¬í•©ë‹ˆë‹¤. í…ŒìŠ¤íŠ¸ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤...")
    #         main_test()
    #     else:
    #         print("ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤. í›ˆë ¨ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
    #         main_training()
    # else:
    #     print("âŒ ì˜ëª»ëœ ì„ íƒì…ë‹ˆë‹¤.")


if __name__ == "__main__":
    main()