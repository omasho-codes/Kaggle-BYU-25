{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":91249,"databundleVersionId":11294684,"sourceType":"competition"},{"sourceId":224916709,"sourceType":"kernelVersion"},{"sourceId":226368929,"sourceType":"kernelVersion"},{"sourceId":327336,"sourceType":"modelInstanceVersion","modelInstanceId":274744,"modelId":295634},{"sourceId":399430,"sourceType":"modelInstanceVersion","modelInstanceId":326904,"modelId":347800},{"sourceId":399523,"sourceType":"modelInstanceVersion","modelInstanceId":326978,"modelId":347876},{"sourceId":410998,"sourceType":"modelInstanceVersion","modelInstanceId":335562,"modelId":356579},{"sourceId":416375,"sourceType":"modelInstanceVersion","modelInstanceId":339700,"modelId":360812},{"sourceId":416428,"sourceType":"modelInstanceVersion","modelInstanceId":339744,"modelId":360862},{"sourceId":416664,"sourceType":"modelInstanceVersion","modelInstanceId":335562,"modelId":356579},{"sourceId":423379,"sourceType":"modelInstanceVersion","modelInstanceId":345034,"modelId":366323}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!tar xfvz /kaggle/input/ultralytics-for-offline-install/archive.tar.gz\n!pip install --no-index --find-links=./packages ultralytics\n!rm -rf ./packages","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T16:30:16.381631Z","iopub.execute_input":"2025-06-03T16:30:16.381841Z","execution_failed":"2025-06-03T16:30:18.183Z"}},"outputs":[{"name":"stdout","text":"./packages/\n./packages/networkx-3.4.2-py3-none-any.whl\n./packages/fsspec-2025.2.0-py3-none-any.whl\n./packages/python_dateutil-2.9.0.post0-py2.py3-none-any.whl\n./packages/jinja2-3.1.5-py3-none-any.whl\n./packages/pyparsing-3.2.1-py3-none-any.whl\n./packages/charset_normalizer-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n./packages/ultralytics_thop-2.0.14-py3-none-any.whl\n./packages/nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl\n./packages/urllib3-2.3.0-py3-none-any.whl\n./packages/nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl\n./packages/pytz-2025.1-py2.py3-none-any.whl\n./packages/MarkupSafe-3.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n./packages/numpy-2.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"!pip install --no-index --find-links=offline_packages onnxsim onnxruntime-gpu onnxslim\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!cp -r /kaggle/input/junhans_yolo11m/other/default/1 onnx","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T16:01:13.264860Z","iopub.execute_input":"2025-06-03T16:01:13.265107Z","iopub.status.idle":"2025-06-03T16:01:13.938526Z","shell.execute_reply.started":"2025-06-03T16:01:13.265083Z","shell.execute_reply":"2025-06-03T16:01:13.937596Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"!pip install ultralytics onnxslim onnxruntime-gpu onnxsim","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T16:01:13.939643Z","iopub.execute_input":"2025-06-03T16:01:13.939957Z","iopub.status.idle":"2025-06-03T16:01:29.379522Z","shell.execute_reply.started":"2025-06-03T16:01:13.939932Z","shell.execute_reply":"2025-06-03T16:01:29.378725Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: ultralytics in /usr/local/lib/python3.10/dist-packages (8.3.80)\nCollecting onnxslim\n  Downloading onnxslim-0.1.56-py3-none-any.whl.metadata (5.5 kB)\nCollecting onnxruntime-gpu\n  Downloading onnxruntime_gpu-1.22.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.9 kB)\nCollecting onnxsim\n  Downloading onnxsim-0.4.36-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.3 kB)\nRequirement already satisfied: numpy<=2.1.1,>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.26.4)\nRequirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.5)\nRequirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.10.0.84)\nRequirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (11.0.0)\nRequirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.2)\nRequirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.32.3)\nRequirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.13.1)\nRequirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.5.1+cu121)\nRequirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.20.1+cu121)\nRequirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.67.1)\nRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\nRequirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\nRequirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.2.3)\nRequirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.12.2)\nRequirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.0.14)\nRequirement already satisfied: onnx in /usr/local/lib/python3.10/dist-packages (from onnxslim) (1.17.0)\nRequirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxslim) (1.13.1)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxslim) (24.2)\nCollecting coloredlogs (from onnxruntime-gpu)\n  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime-gpu) (24.3.25)\nRequirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime-gpu) (3.20.3)\nRequirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from onnxsim) (13.9.4)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.55.3)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.7)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.0)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy<=2.1.1,>=1.23.0->ultralytics) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy<=2.1.1,>=1.23.0->ultralytics) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy<=2.1.1,>=1.23.0->ultralytics) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy<=2.1.1,>=1.23.0->ultralytics) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy<=2.1.1,>=1.23.0->ultralytics) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy<=2.1.1,>=1.23.0->ultralytics) (2.4.1)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2025.1)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2025.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2025.1.31)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.17.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2024.12.0)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxslim) (1.3.0)\nCollecting humanfriendly>=9.1 (from coloredlogs->onnxruntime-gpu)\n  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->onnxsim) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->onnxsim) (2.19.1)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->onnxsim) (0.1.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<=2.1.1,>=1.23.0->ultralytics) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<=2.1.1,>=1.23.0->ultralytics) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy<=2.1.1,>=1.23.0->ultralytics) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy<=2.1.1,>=1.23.0->ultralytics) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy<=2.1.1,>=1.23.0->ultralytics) (2024.2.0)\nDownloading onnxslim-0.1.56-py3-none-any.whl (146 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m146.2/146.2 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading onnxruntime_gpu-1.22.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (283.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m283.2/283.2 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading onnxsim-0.4.36-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m50.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: humanfriendly, coloredlogs, onnxslim, onnxsim, onnxruntime-gpu\nSuccessfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-gpu-1.22.0 onnxsim-0.4.36 onnxslim-0.1.56\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"from ultralytics import YOLO\nmodel = YOLO(\"/kaggle/working/onnx/last.pt\")\nmodel.export(format=\"onnx\", opset=12, device='cuda',dynamic=True,simplify=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T16:01:29.380977Z","iopub.execute_input":"2025-06-03T16:01:29.381274Z","iopub.status.idle":"2025-06-03T16:01:49.392359Z","shell.execute_reply.started":"2025-06-03T16:01:29.381250Z","shell.execute_reply":"2025-06-03T16:01:49.391725Z"}},"outputs":[{"name":"stdout","text":"Creating new Ultralytics Settings v0.0.6 file ✅ \nView Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\nUpdate Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\nUltralytics 8.3.80 🚀 Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla T4, 15095MiB)\nYOLO11m summary (fused): 125 layers, 20,030,803 parameters, 0 gradients, 67.6 GFLOPs\n\n\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '/kaggle/working/onnx/last.pt' with input shape (1, 3, 960, 960) BCHW and output shape(s) (1, 5, 18900) (38.7 MB)\n\n\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.17.0 opset 12...\n\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.56...\n\u001b[34m\u001b[1mONNX:\u001b[0m export success ✅ 9.4s, saved as '/kaggle/working/onnx/last.onnx' (76.6 MB)\n\nExport complete (12.5s)\nResults saved to \u001b[1m/kaggle/working/onnx\u001b[0m\nPredict:         yolo predict task=detect model=/kaggle/working/onnx/last.onnx imgsz=960  \nValidate:        yolo val task=detect model=/kaggle/working/onnx/last.onnx imgsz=960 data=./fixed_dataset.yaml  \nVisualize:       https://netron.app\n","output_type":"stream"},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working/onnx/last.onnx'"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"model_path = \"/kaggle/working/onnx/last.onnx\"\nCONFIDENCE_THRESHOLD = 0.3\nMAX_DETECTIONS_PER_TOMO = 1\nNMS_IOU_THRESHOLD = 0.2\nCONCENTRATION = 0.5\nBATCH_SIZE = 8 \n\nimport os\nfrom pathlib import Path\nimport os\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nimport torch\nimport cv2\nfrom tqdm.notebook import tqdm\nfrom ultralytics import YOLO\nimport threading\nimport time\nfrom contextlib import nullcontext\nfrom concurrent.futures import ThreadPoolExecutor\n\nfrom pathlib import Path\n\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.utils.data import DataLoader, TensorDataset\n\n\n\nnp.random.seed(42)\ntorch.manual_seed(42)\n\n\ndata_path = \"/kaggle/input/byu-locating-bacterial-flagellar-motors-2025/\"\ntest_dir = os.path.join(data_path, \"test\")\nsubmission_path = \"/kaggle/working/submission.csv\"\n\ndevice = 'cuda:0' if torch.cuda.is_available() else 'cpu'\nif device.startswith('cuda'):\n    torch.backends.cudnn.benchmark = True\n    torch.backends.cudnn.deterministic = False\n    torch.backends.cuda.matmul.allow_tf32 = True\n    torch.backends.cudnn.allow_tf32 = True\n\n# AMP scaler for inference (no scaling)\nscaler = torch.cuda.amp.GradScaler(enabled=False)\n\nclass GPUProfiler:\n    def __init__(self, name):\n        self.name = name\n        self.start_time = None\n    def __enter__(self):\n        if torch.cuda.is_available(): torch.cuda.synchronize()\n        self.start_time = time.time()\n    def __exit__(self, *args):\n        if torch.cuda.is_available(): torch.cuda.synchronize()\n        elapsed = time.time() - self.start_time\n        # print(f\"[PROFILE] {self.name}: {elapsed:.3f}s\")\n\n\ndef perform_3d_nms(detections, iou_threshold):\n    \"\"\"\n    Perform 3D Non-Maximum Suppression on detections to merge nearby motors\n    \"\"\"\n    if not detections:\n        return []\n    \n    # Sort by confidence (highest first)\n    detections = sorted(detections, key=lambda x: x['confidence'], reverse=True)\n    \n    # List to store final detections after NMS\n    final_detections = []\n    \n    # Define 3D distance function\n    def distance_3d(d1, d2):\n        return np.sqrt((d1['z'] - d2['z'])**2 + \n                       (d1['y'] - d2['y'])**2 + \n                       (d1['x'] - d2['x'])**2)\n    \n    # Maximum distance threshold (based on box size and slice gap)\n    box_size = 24  # Same as annotation box size\n    distance_threshold = box_size * iou_threshold\n    \n    # Process each detection\n    while detections:\n        # Take the detection with highest confidence\n        best_detection = detections.pop(0)\n        final_detections.append(best_detection)\n        return final_detections\n    #     # Filter out detections that are too close to the best detection\n        # detections = [d for d in detections if distance_3d(d, best_detection) > distance_threshold]\n    \n    return final_detections\n\n\nfrom concurrent.futures import ThreadPoolExecutor\n\nclass TomogramSliceDataset(Dataset):\n    def __init__(self, paths, batch_size):\n        self.paths = paths\n        self.batch_size = batch_size\n\n    def __len__(self):\n        return len(self.paths) // self.batch_size\n\n    def load_and_process(self, p):\n        img = cv2.imread(p)\n        # img = cv2.medianBlur(img, ksize=5)\n        return img\n    def __getitem__(self, idx):\n        start = idx * self.batch_size\n        end = (idx + 1) * self.batch_size\n        p_batch = self.paths[start:end]\n        with ThreadPoolExecutor(max_workers=14) as executor:\n            imgs = list(executor.map(self.load_and_process, p_batch))\n    \n        return list(range(start, end)), imgs\n\n    @staticmethod\n    def collate_fn(batch):\n        paths, imgs = zip(*batch)\n        return list(paths), list(imgs)\n\n\n\n\n@torch.no_grad()\ndef process_tomogram(tomo_id, model, total, idx):\n    \n    tomo_path = os.path.join(test_dir, tomo_id)\n    files = sorted([f for f in os.listdir(tomo_path) if f.endswith('.jpg')])\n    sel = np.linspace(0, len(files)-1, int(len(files)*CONCENTRATION)).round().astype(int)\n    files = [files[i] for i in sel]\n    paths = [os.path.join(tomo_path, f) for f in files]\n    slice_nums = [int(f.split('_')[1].split('.')[0]) for f in files]\n\n    ds = TomogramSliceDataset(paths, batch_size=32)\n    loader = DataLoader(ds, batch_size=1, shuffle=False,\n                        num_workers=1, pin_memory=True,\n                        collate_fn=TomogramSliceDataset.collate_fn)\n    \n\n    all_dets = []\n    # volm = []\n    for batch_zidx, imgs in loader:\n        imgs = imgs[0]\n        batch_zidx = batch_zidx[0]\n        # print(len(imgs))\n        with GPUProfiler(f\"Inference {len(batch_zidx)} slices\"):\n            with torch.cuda.amp.autocast():\n                # print(imgs[0].shape)\n                    # model.predict(source=\"img.jpg\", device=0)\n\n                preds = model.predict(imgs,device='cuda', verbose=False)\n        torch.cuda.empty_cache()\n        for z, result in zip(batch_zidx, preds):\n            z = slice_nums.pop(0)\n            if len(result.boxes) > 0 and result.boxes.conf[0] >= CONFIDENCE_THRESHOLD :\n                x1,y1,x2,y2 = result.boxes.xyxy[0].cpu().numpy()\n                all_dets.append({\n                            'z': z,\n                            'y': int(round((y1+y2)/2)),\n                            'x': int(round((x1+x2)/2)),\n                            'confidence': float(result.boxes.conf[0])\n                        })\n           \n    # if device.startswith('cuda'): torch.cuda.synchronize()\n    final = perform_3d_nms(all_dets, NMS_IOU_THRESHOLD)\n    # final.sort(key=lambda x: x['confidence'], reverse=True)\n    if not final:\n        return {'tomo_id': tomo_id, 'Motor axis 0': -1,\n                'Motor axis 1': -1, 'Motor axis 2': -1}\n        \n    # if len(all_dets)<2:\n    #     return {'tomo_id': tomo_id, 'Motor axis 0': -1,\n    #             'Motor axis 1': -1, 'Motor axis 2': -1}\n        \n    best = final[0]\n    return {'tomo_id': tomo_id,\n            'Motor axis 0': best['z'],\n            'Motor axis 1': best['y'],\n            'Motor axis 2': best['x']}\n\n\ndef generate_submission():\n    tomos = sorted([d for d in os.listdir(test_dir) if os.path.isdir(os.path.join(test_dir, d))])\n    model = YOLO(model_path)\n    # model.to(device)\n    # if device.startswith('cuda'):\n    #     model.fuse()\n    #     if torch.cuda.get_device_capability(0)[0] >= 7:\n    #         model.model.half()\n\n    results = []\n    for idx, tomo in enumerate(tqdm(tomos, desc=\"Tomo loop\"), 1):\n        torch.cuda.empty_cache()\n        res = process_tomogram(tomo, model, len(tomos), idx)\n        results.append(res)\n\n    df = pd.DataFrame(results)[['tomo_id','Motor axis 0','Motor axis 1','Motor axis 2']]\n    df.to_csv(submission_path, index=False)\n    print(df.head())\n    return df\n\nif __name__ == \"__main__\":\n    start = time.time()\n    generate_submission()\n    print(f\"Total time: {time.time()-start:.2f}s\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T16:01:49.393354Z","iopub.execute_input":"2025-06-03T16:01:49.393711Z","iopub.status.idle":"2025-06-03T16:01:52.833849Z","shell.execute_reply.started":"2025-06-03T16:01:49.393688Z","shell.execute_reply":"2025-06-03T16:01:52.832649Z"}},"outputs":[{"name":"stdout","text":"WARNING ⚠️ Unable to automatically guess model task, assuming 'task=detect'. Explicitly define task for your model, i.e. 'task=detect', 'segment', 'classify','pose' or 'obb'.\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-5-650aa9cef167>:46: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = torch.cuda.amp.GradScaler(enabled=False)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Tomo loop:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Ultralytics 8.3.80 🚀 Python-3.10.12 torch-2.5.1+cu121 \n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-5-650aa9cef167>:147: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast():\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-650aa9cef167>\u001b[0m in \u001b[0;36m<cell line: 202>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m     \u001b[0mgenerate_submission\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Total time: {time.time()-start:.2f}s\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-5-650aa9cef167>\u001b[0m in \u001b[0;36mgenerate_submission\u001b[0;34m()\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtomo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtomos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Tomo loop\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_tomogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtomo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtomos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m         \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-5-650aa9cef167>\u001b[0m in \u001b[0;36mprocess_tomogram\u001b[0;34m(tomo_id, model, total, idx)\u001b[0m\n\u001b[1;32m    149\u001b[0m                     \u001b[0;31m# model.predict(source=\"img.jpg\", device=0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m                 \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'0,1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_zidx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/engine/model.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, source, stream, predictor, **kwargs)\u001b[0m\n\u001b[1;32m    551\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpredictor\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_smart_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"predictor\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_callbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 553\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_cli\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    554\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# only update args if predictor is already setup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_cfg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/engine/predictor.py\u001b[0m in \u001b[0;36msetup_model\u001b[0;34m(self, model, verbose)\u001b[0m\n\u001b[1;32m    310\u001b[0m         self.model = AutoBackend(\n\u001b[1;32m    311\u001b[0m             \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m             \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mselect_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m             \u001b[0mdnn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdnn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/utils/torch_utils.py\u001b[0m in \u001b[0;36mselect_device\u001b[0;34m(device, batch, newline, verbose)\u001b[0m\n\u001b[1;32m    190\u001b[0m                 \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m             )\n\u001b[0;32m--> 192\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    193\u001b[0m                 \u001b[0;34mf\"Invalid CUDA 'device={device}' requested.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m                 \u001b[0;34mf\" Use 'device=cpu' or pass valid CUDA device(s) if available,\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Invalid CUDA 'device=0,1' requested. Use 'device=cpu' or pass valid CUDA device(s) if available, i.e. 'device=0' or 'device=0,1,2,3' for Multi-GPU.\n\ntorch.cuda.is_available(): True\ntorch.cuda.device_count(): 1\nos.environ['CUDA_VISIBLE_DEVICES']: 0\n"],"ename":"ValueError","evalue":"Invalid CUDA 'device=0,1' requested. Use 'device=cpu' or pass valid CUDA device(s) if available, i.e. 'device=0' or 'device=0,1,2,3' for Multi-GPU.\n\ntorch.cuda.is_available(): True\ntorch.cuda.device_count(): 1\nos.environ['CUDA_VISIBLE_DEVICES']: 0\n","output_type":"error"}],"execution_count":5},{"cell_type":"code","source":"model_path = \"/kaggle/input/junhans_yolo11m/other/default/1/last.pt\"\nCONFIDENCE_THRESHOLD = 0.7\nMAX_DETECTIONS_PER_TOMO = 1\nNMS_IOU_THRESHOLD = 0.2\nCONCENTRATION = 0.5\nBATCH_SIZE = 8 \n\nimport os\nfrom pathlib import Path\n\n# current_dir = Path.cwd()\n# print(\"this_dir:\", current_dir)\n\n# target_dir = Path(\"/kaggle/working/MHAF-YOLO-main\") \n# os.chdir(target_dir)  \n\nimport os\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nimport torch\nimport cv2\nfrom tqdm.notebook import tqdm\nfrom ultralytics import YOLO\nimport threading\nimport time\nfrom contextlib import nullcontext\nfrom concurrent.futures import ThreadPoolExecutor\n\nfrom pathlib import Path\n\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.utils.data import DataLoader, TensorDataset\n\n\n\nnp.random.seed(42)\ntorch.manual_seed(42)\n\n\ndata_path = \"/kaggle/input/byu-locating-bacterial-flagellar-motors-2025/\"\ntest_dir = os.path.join(data_path, \"test\")\nsubmission_path = \"/kaggle/working/submission.csv\"\n\ndevice = 'cuda:0' if torch.cuda.is_available() else 'cpu'\nif device.startswith('cuda'):\n    torch.backends.cudnn.benchmark = True\n    torch.backends.cudnn.deterministic = False\n    torch.backends.cuda.matmul.allow_tf32 = True\n    torch.backends.cudnn.allow_tf32 = True\n\n# AMP scaler for inference (no scaling)\nscaler = torch.cuda.amp.GradScaler(enabled=False)\n\nclass GPUProfiler:\n    def __init__(self, name):\n        self.name = name\n        self.start_time = None\n    def __enter__(self):\n        if torch.cuda.is_available(): torch.cuda.synchronize()\n        self.start_time = time.time()\n    def __exit__(self, *args):\n        if torch.cuda.is_available(): torch.cuda.synchronize()\n        elapsed = time.time() - self.start_time\n        # print(f\"[PROFILE] {self.name}: {elapsed:.3f}s\")\n\n\ndef perform_3d_nms(detections, iou_threshold):\n    \"\"\"\n    Perform 3D Non-Maximum Suppression on detections to merge nearby motors\n    \"\"\"\n    if not detections:\n        return []\n    \n    # Sort by confidence (highest first)\n    detections = sorted(detections, key=lambda x: x['confidence'], reverse=True)\n    \n    # List to store final detections after NMS\n    final_detections = []\n    \n    # Define 3D distance function\n    def distance_3d(d1, d2):\n        return np.sqrt((d1['z'] - d2['z'])**2 + \n                       (d1['y'] - d2['y'])**2 + \n                       (d1['x'] - d2['x'])**2)\n    \n    # Maximum distance threshold (based on box size and slice gap)\n    box_size = 24  # Same as annotation box size\n    distance_threshold = box_size * iou_threshold\n    \n    # Process each detection\n    while detections:\n        # Take the detection with highest confidence\n        best_detection = detections.pop(0)\n        final_detections.append(best_detection)\n        return final_detections\n    #     # Filter out detections that are too close to the best detection\n        # detections = [d for d in detections if distance_3d(d, best_detection) > distance_threshold]\n    \n    return final_detections\n\n\nclass TomogramSliceDataset(Dataset):\n    def __init__(self, paths, target_size=(960,960)):\n        self.paths = paths\n        self.target_size = target_size\n    def __len__(self):\n        return len(self.paths)\n    def __getitem__(self, idx):   \n        p = self.paths[idx]\n        img = cv2.imread(p)\n        img = cv2.medianBlur(img, ksize=5)  # Kernel size must be odd\n        if img is None:\n            img = np.array(Image.open(p))\n        # Resize to target size to limit GPU memory usage\n        # img = cv2.resize(img, self.target_size, interpolation=cv2.INTER_AREA)\n        # img = torch.from_numpy(img)\n        return idx, img\n\n    @staticmethod\n    def collate_fn(batch):\n        paths, imgs = zip(*batch)\n        return list(paths), list(imgs)\n\n\n\n@torch.no_grad()\ndef process_tomogram(tomo_id, model, total, idx):\n    tomo_path = os.path.join(test_dir, tomo_id)\n    files = sorted([f for f in os.listdir(tomo_path) if f.endswith('.jpg')])\n    sel = np.linspace(0, len(files)-1, int(len(files)*CONCENTRATION)).round().astype(int)\n    files = [files[i] for i in sel]\n    paths = [os.path.join(tomo_path, f) for f in files]\n    slice_nums = [int(f.split('_')[1].split('.')[0]) for f in files]\n\n    ds = TomogramSliceDataset(paths)\n    loader = DataLoader(ds, batch_size=32, shuffle=False,\n                        num_workers=4, pin_memory=True,\n                        collate_fn=TomogramSliceDataset.collate_fn)\n\n    all_dets = []\n    # volm = []\n    for batch_zidx, imgs in loader:\n        with GPUProfiler(f\"Inference {len(batch_zidx)} slices\"):\n            with torch.cuda.amp.autocast():\n                preds = model(imgs, verbose=False)\n        \n        # imgs = np.concatenate(imgs, axis=0)\n        # (B,H, W) = im/gs.shape\n        # volm.append(imgs.reshape(-1, H, W))\n        for z, result in zip(batch_zidx, preds):\n            z = slice_nums.pop(0)\n            if len(result.boxes) > 0 and result.boxes.conf[0] >= CONFIDENCE_THRESHOLD :\n                x1,y1,x2,y2 = result.boxes.xyxy[0].cpu().numpy()\n                all_dets.append({\n                            'z': z,\n                            'y': int(round((y1+y2)/2)),\n                            'x': int(round((x1+x2)/2)),\n                            'confidence': float(result.boxes.conf[0])\n                        })\n           \n    # if device.startswith('cuda'): torch.cuda.synchronize()\n    final = perform_3d_nms(all_dets, NMS_IOU_THRESHOLD)\n    # final.sort(key=lambda x: x['confidence'], reverse=True)\n    if not final:\n        return {'tomo_id': tomo_id, 'Motor axis 0': -1,\n                'Motor axis 1': -1, 'Motor axis 2': -1}\n        \n    # if len(all_dets)<2:\n    #     return {'tomo_id': tomo_id, 'Motor axis 0': -1,\n    #             'Motor axis 1': -1, 'Motor axis 2': -1}\n        \n    best = final[0]\n    return {'tomo_id': tomo_id,\n            'Motor axis 0': best['z'],\n            'Motor axis 1': best['y'],\n            'Motor axis 2': best['x']}\n\n\ndef generate_submission():\n    tomos = sorted([d for d in os.listdir(test_dir) if os.path.isdir(os.path.join(test_dir, d))])\n    model = YOLO(model_path)\n    model.to(device)\n    if device.startswith('cuda'):\n        model.fuse()\n        if torch.cuda.get_device_capability(0)[0] >= 7:\n            model.model.half()\n\n    results = []\n    for idx, tomo in enumerate(tqdm(tomos, desc=\"Tomo loop\"), 1):\n        torch.cuda.empty_cache()\n        res = process_tomogram(tomo, model, len(tomos), idx)\n        results.append(res)\n\n    df = pd.DataFrame(results)[['tomo_id','Motor axis 0','Motor axis 1','Motor axis 2']]\n    df.to_csv(submission_path, index=False)\n    print(df.head())\n    return df\n\nif __name__ == \"__main__\":\n    start = time.time()\n    generate_submission()\n    print(f\"Total time: {time.time()-start:.2f}s\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T16:01:52.834407Z","iopub.status.idle":"2025-06-03T16:01:52.834692Z","shell.execute_reply":"2025-06-03T16:01:52.834554Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# !cp -r /kaggle/input/mhafyolo/pytorch/default/1/MHAF-YOLO-main /kaggle/working/\n# model_path = \"/kaggle/input/mhaf_2.5d/onnx/default/1/best (11).pt\"\n# CONFIDENCE_THRESHOLD = 0.3\n# MAX_DETECTIONS_PER_TOMO = 1 # This seems to be handled by perform_3d_nms returning only one\n# NMS_IOU_THRESHOLD = 0.2\n# CONCENTRATION = 1 # This determines how many center slices we'll consider\n# BATCH_SIZE = 8 # Adjust based on GPU memory for 3-channel images\n# STACK_STRIDE = 2 # For z-2, z, z+2. Results in a 3-channel image.\n# # If you change STACK_STRIDE, ensure your model's first layer can handle the number of input channels if it's not 3.\n# # For this example, we are creating a 3-channel image.\n\n# import os\n# from pathlib import Path\n# import shutil # For potential future use\n\n# current_dir = Path.cwd()\n# print(\"this_dir:\", current_dir)\n\n# target_dir = Path(\"/kaggle/working/MHAF-YOLO-main\")\n# # if not target_dir.exists():\n# #     # Assuming you have a way to get MHAF-YOLO-main, e.g., from another input or git clone\n# #     # For now, let's mock its creation if it's just about running the script\n# #     # In a real Kaggle notebook, you'd copy it from an input source\n# #     print(f\"{target_dir} does not exist. Please ensure it's available or copied.\")\n# #     # Example: shutil.copytree(\"/kaggle/input/your-mhaf-yolo-repo\", target_dir)\n# #     target_dir.mkdir(parents=True, exist_ok=True) # Create if not exists for now\n# # else:\n# #     print(f\"Target directory {target_dir} already exists.\")\n\n# os.chdir(target_dir)\n# print(f\"Changed CWD to: {Path.cwd()}\")\n\n\n# import numpy as np\n# import pandas as pd\n# from PIL import Image\n# import torch\n# import cv2\n# from tqdm.notebook import tqdm\n# from ultralytics import YOLOv10 # Assuming this is the correct import for your model\n# import threading # Not actively used in the final version, can be removed\n# import time\n# from contextlib import nullcontext # Not actively used, can be removed\n# from concurrent.futures import ThreadPoolExecutor # Not actively used, can be removed\n\n# from torch.utils.data import Dataset, DataLoader\n# # from torch.utils.data import DataLoader, TensorDataset # Redundant import\n\n# np.random.seed(42)\n# torch.manual_seed(42)\n\n# data_path = \"/kaggle/input/byu-locating-bacterial-flagellar-motors-2025/\"\n# test_dir = os.path.join(data_path, \"test\")\n# submission_path = \"/kaggle/working/submission.csv\"\n\n# device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n# if device.startswith('cuda'):\n#     torch.backends.cudnn.benchmark = True\n#     torch.backends.cudnn.deterministic = False # Usually False for speed\n#     torch.backends.cuda.matmul.allow_tf32 = True\n#     torch.backends.cudnn.allow_tf32 = True\n\n# # AMP scaler for inference (no scaling if enabled=False)\n# scaler = torch.cuda.amp.GradScaler(enabled=torch.cuda.is_available()) # Enable if using AMP\n\n# class GPUProfiler:\n#     def __init__(self, name):\n#         self.name = name\n#         self.start_time = None\n#     def __enter__(self):\n#         if torch.cuda.is_available(): torch.cuda.synchronize()\n#         self.start_time = time.time()\n#     def __exit__(self, *args):\n#         if torch.cuda.is_available(): torch.cuda.synchronize()\n#         elapsed = time.time() - self.start_time\n#         # print(f\"[PROFILE] {self.name}: {elapsed:.3f}s\")\n\n\n# def perform_3d_nms(detections, iou_threshold):\n#     if not detections:\n#         return []\n#     detections = sorted(detections, key=lambda x: x['confidence'], reverse=True)\n#     final_detections = []\n    \n#     # Simplified NMS: if we only want MAX_DETECTIONS_PER_TOMO = 1,\n#     # we just take the highest confidence one after initial filtering.\n#     # The original code for NMS was more complex than needed if only one detection is kept.\n#     if detections: # If there's at least one detection\n#         final_detections.append(detections[0]) # Take the best one\n#         return final_detections\n\n\n# class TomogramSliceDataset25D(Dataset):\n#     def __init__(self, tomo_id_path, center_slice_filenames_with_paths, all_slices_in_tomo_map, \n#                  stack_stride, target_size=(960, 960)):\n#         self.tomo_id_path = tomo_id_path # Path to the tomogram directory\n#         self.center_slice_info = center_slice_filenames_with_paths # List of (abs_path, slice_idx) for center slices\n#         self.all_slices_in_tomo_map = all_slices_in_tomo_map # Map: slice_idx -> abs_path for all slices\n#         self.stack_stride = stack_stride\n#         self.target_size = target_size\n#         self.num_channels = 3 # Since we are stacking 3 slices (z-stride, z, z+stride)\n\n#     def __len__(self):\n#         return len(self.center_slice_info)\n\n#     def _load_slice(self, slice_idx):\n#         \"\"\"Loads a single slice, handling boundaries by clamping and reusing edge slices.\"\"\"\n#         # Find the closest available slice if exact index is out of bounds for stacking\n#         min_available_idx = min(self.all_slices_in_tomo_map.keys())\n#         max_available_idx = max(self.all_slices_in_tomo_map.keys())\n        \n#         clamped_idx = np.clip(slice_idx, min_available_idx, max_available_idx)\n        \n#         slice_path = self.all_slices_in_tomo_map.get(clamped_idx)\n\n#         if slice_path is None: # Should not happen if map is complete for the tomogram\n#             print(f\"Warning: Slice for index {clamped_idx} (original {slice_idx}) not found in map. Returning zeros.\")\n#             return np.zeros((*self.target_size, 1), dtype=np.uint8) # H, W, C (grayscale)\n\n#         try:\n#             # img = cv2.imread(slice_path, cv2.IMREAD_GRAYSCALE) # Read as grayscale\n#             # Using PIL as it was in original snippet for one path\n#             img = Image.open(slice_path) # Convert to grayscale\n#             img = np.array(img)\n\n#             if img is None:\n#                 raise ValueError(f\"cv2.imread failed for {slice_path}\")\n#             # return img\n#             # if img.shape[:2] != self.target_size: # Check if resize is needed\n#                  # img = cv2.resize(img, self.target_size, interpolation=cv2.INTER_AREA)\n#             return img[:, :, np.newaxis] # Add channel dim: H, W, 1\n#         except Exception as e:\n#             print(f\"Error loading/processing slice {slice_path} for index {slice_idx}: {e}. Returning zeros.\")\n#             return np.zeros((*self.target_size, 1), dtype=np.uint8)\n\n\n#     def __getitem__(self, idx):\n#         center_slice_path, center_slice_z_idx = self.center_slice_info[idx]\n        \n#         slices_to_stack = []\n#         # Slice indices for the stack: [z - stride, z, z + stride]\n#         slice_indices = [\n#             center_slice_z_idx - self.stack_stride,\n#             center_slice_z_idx,\n#             center_slice_z_idx + self.stack_stride,\n#         ]\n\n#         for z_val in slice_indices:\n#             slices_to_stack.append(self._load_slice(z_val))\n        \n#         # Stack along the channel dimension (last dimension)\n#         stacked_img = np.concatenate(slices_to_stack, axis=2) # Shape: H, W, 3\n\n#         # YOLO typically expects CHW format if using PyTorch transforms,\n#         # but the model.predict() often handles HWC for NumPy arrays.\n#         # If you need to convert to CHW:\n#         # stacked_img = np.transpose(stacked_img, (2, 0, 1)) # Shape: 3, H, W\n#         # stacked_img = torch.from_numpy(stacked_img).float() / 255.0 # Normalize if needed\n\n#         # The model.predict() in ultralytics often takes HWC numpy arrays.\n#         return center_slice_z_idx, stacked_img # Return center_z_idx for this stack\n\n#     @staticmethod\n#     def collate_fn(batch):\n#         # center_z_indices, stacked_images = zip(*batch)\n#         # return list(center_z_indices), list(stacked_images) # Pass as list of numpy arrays\n#         # Default collate should work if __getitem__ returns (int, np.ndarray)\n#         # It will stack the numpy arrays along a new batch dimension.\n#         # If returning PyTorch tensors, default collate is also fine.\n#         center_z_indices, stacked_images_list = zip(*batch)\n#         # Assuming stacked_images_list contains HWC numpy arrays\n#         # Convert to a single batch tensor if model expects that, or pass list\n#         return list(center_z_indices), stacked_images_list\n\n\n# @torch.no_grad()\n# def process_tomogram(tomo_id, model, total_tomos, current_tomo_idx): # Renamed args for clarity\n#     tomo_dir_path = Path(test_dir) / tomo_id\n    \n#     # Get all available .jpg slices and their integer indices for this tomogram\n#     all_slice_files = sorted(tomo_dir_path.glob('*.jpg'))\n#     if not all_slice_files:\n#         print(f\"No jpg files found in {tomo_dir_path}\")\n#         return {'tomo_id': tomo_id, 'Motor axis 0': -1, 'Motor axis 1': -1, 'Motor axis 2': -1}\n\n#     all_slices_map = {} # Map from Z-index to absolute path\n#     for f_path in all_slice_files:\n#         try:\n#             slice_idx = int(f_path.stem.split('_')[1])\n#             all_slices_map[slice_idx] = str(f_path)\n#         except (IndexError, ValueError):\n#             print(f\"Could not parse slice index from filename: {f_path.name}\")\n#             continue\n    \n#     if not all_slices_map:\n#         print(f\"Could not parse any slice indices for tomogram {tomo_id}\")\n#         return {'tomo_id': tomo_id, 'Motor axis 0': -1, 'Motor axis 1': -1, 'Motor axis 2': -1}\n\n#     # Determine which slices will be the *center* of a 2.5D stack\n#     # These are the Z-coordinates we will effectively \"scan\"\n#     # CONCENTRATION determines sampling of these center slices\n#     center_slice_indices_available = sorted(all_slices_map.keys())\n#     num_center_slices_to_consider = int(len(center_slice_indices_available) * CONCENTRATION)\n#     if num_center_slices_to_consider == 0 and len(center_slice_indices_available) > 0:\n#         num_center_slices_to_consider = 1 # Ensure at least one if possible\n\n#     selected_center_indices_for_stacking = np.linspace(\n#         0, \n#         len(center_slice_indices_available) - 1, \n#         num_center_slices_to_consider\n#     ).round().astype(int)\n    \n#     center_slices_info_for_dataset = [] # List of (abs_path_of_center_slice, center_slice_z_idx)\n#     for sel_idx in selected_center_indices_for_stacking:\n#         actual_z_idx = center_slice_indices_available[sel_idx]\n#         center_slices_info_for_dataset.append((all_slices_map[actual_z_idx], actual_z_idx))\n\n#     if not center_slices_info_for_dataset:\n#         print(f\"No center slices selected for processing for tomogram {tomo_id}\")\n#         return {'tomo_id': tomo_id, 'Motor axis 0': -1, 'Motor axis 1': -1, 'Motor axis 2': -1}\n\n#     # Create dataset and dataloader for 2.5D stacks\n#     # Hardcoding target_size, can be a parameter\n#     target_img_size = (model.model.yaml.get('imgsz', [960, 960]))[0] # Get imgsz from model if possible\n#     if isinstance(target_img_size, list): target_img_size = target_img_size[0] # e.g. [960,960]\n#     # If your images are not square, and model expects square, you might need padding.\n#     # For now, assuming resize to a square shape like (960,960) or (960,960) from original TomogramSliceDataset.\n#     # Using (960,960) from original TomogramSliceDataset. For YOLO, it's often (960,960)\n#     # Let's use a common YOLO size, but ensure your model is trained/fine-tuned on it.\n#     # For inference, it's best to match training size.\n#     # The model.predict() usually handles resizing internally if you provide `imgsz` argument.\n#     # Here, we are pre-resizing in the dataset. This might be useful if original images are huge.\n#     # Let's make target_size consistent with a typical YOLO input.\n#     # For consistency with original code, use (960,960), but be mindful of model training size.\n#     # For YOLO, often 960. If model.predict resizes, then dataset resize is redundant.\n#     # For now, let's assume we do want to resize in dataset.\n#     dataset_target_size = (960, 960) # Example, adjust as needed for your model and performance.\n\n#     ds = TomogramSliceDataset25D(str(tomo_dir_path), center_slices_info_for_dataset, all_slices_map, \n#                                  STACK_STRIDE, target_size=dataset_target_size)\n    \n#     loader = DataLoader(ds, batch_size=BATCH_SIZE, shuffle=False,\n#                         num_workers=min(os.cpu_count(), 4), # More robust num_workers\n#                         pin_memory=True if device.startswith('cuda') else False,\n#                         collate_fn=TomogramSliceDataset25D.collate_fn)\n\n#     all_dets = []\n#     for batch_center_z_indices, batch_stacked_imgs_list in loader:\n#         # batch_stacked_imgs_list is a list of HWC numpy arrays\n#         # model.predict can usually take a list of images\n#         with GPUProfiler(f\"Inference {len(batch_stacked_imgs_list)} stacks\"):\n#             # AMP context manager for inference\n#             with torch.cuda.amp.autocast(enabled=device.startswith('cuda')):\n#                  # verbose=False, imgsz=dataset_target_size (or let model use its default)\n#                 preds = model(batch_stacked_imgs_list, verbose=False)\n        \n#         for center_z, result in zip(batch_center_z_indices, preds):\n#             # 'center_z' is the Z-index of the central slice of the stack\n#             if len(result.boxes) > 0 and result.boxes.conf[0] >= CONFIDENCE_THRESHOLD:\n#                 x1,y1,x2,y2 = result.boxes.xyxy[0].cpu().numpy()\n#                 final_y = int(round((y1+y2)/2))\n#                 final_x = int(round((x1+x2)/2))\n\n#                 all_dets.append({\n#                     'z': center_z, # Z-coordinate of the center of the stack\n#                     'y': final_y,\n#                     'x': final_x,\n#                     'confidence': float(result.boxes.conf[0])\n#                 })\n           \n#     final_detections_after_nms = perform_3d_nms(all_dets, NMS_IOU_THRESHOLD)\n    \n#     if not final_detections_after_nms:\n#         return {'tomo_id': tomo_id, 'Motor axis 0': -1,\n#                 'Motor axis 1': -1, 'Motor axis 2': -1}\n        \n#     best_detection = final_detections_after_nms[0]\n#     return {'tomo_id': tomo_id,\n#             'Motor axis 0': best_detection['z'],\n#             'Motor axis 1': best_detection['y'],\n#             'Motor axis 2': best_detection['x']}\n\n\n# def generate_submission():\n#     tomos = sorted([d for d in os.listdir(test_dir) if os.path.isdir(os.path.join(test_dir, d))])\n#     # tomos = tomos[:3] # For quick testing\n\n#     print(f\"Loading model from {model_path}...\")\n#     model = YOLOv10(model_path) # Use YOLO class\n#     model.to(device)\n    \n#     # Model optimization (optional, but good for inference speed)\n#     # model.fuse() # Fuse conv-bn layers, standard optimization\n#     # If using half precision\n#     if device.startswith('cuda') and torch.cuda.is_available() and torch.cuda.get_device_capability(0)[0] >= 7:\n#         print(\"Using half precision for model.\")\n#         model.half() # model.model.half() is for older ultralytics versions\n#     else:\n#         print(\"Not using half precision (either no CUDA, old GPU, or device check failed).\")\n\n\n#     results_list = []\n#     for idx, tomo_id_str in enumerate(tqdm(tomos, desc=\"Processing Tomograms\"), 1):\n#         if device.startswith('cuda') and torch.cuda.is_available(): # Check CUDA availability again\n#             torch.cuda.empty_cache()\n        \n#         # Pass total_tomos and current_tomo_idx if needed by process_tomogram\n#         single_tomo_result = process_tomogram(tomo_id_str, model, len(tomos), idx)\n#         results_list.append(single_tomo_result)\n\n#     submission_df = pd.DataFrame(results_list)[['tomo_id','Motor axis 0','Motor axis 1','Motor axis 2']]\n#     submission_df.to_csv(submission_path, index=False)\n#     print(\"\\nSubmission file created:\")\n#     print(submission_df.head())\n#     return submission_df\n\n# if __name__ == \"__main__\":\n#     # Ensure CWD is correct if MHAF-YOLO has specific requirements\n#     # (already handled at the top of the script by os.chdir(target_dir))\n    \n#     print(f\"Running on device: {device}\")\n#     if device.startswith('cuda') and not torch.cuda.is_available():\n#         print(\"Warning: Device set to CUDA but CUDA is not available. PyTorch will use CPU.\")\n#         device = 'cpu' # Fallback if check fails later\n\n#     start_time = time.time()\n#     generate_submission()\n#     end_time = time.time()\n#     print(f\"\\nTotal processing time: {end_time - start_time:.2f} seconds\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T16:01:52.835415Z","iopub.status.idle":"2025-06-03T16:01:52.835722Z","shell.execute_reply":"2025-06-03T16:01:52.835560Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}