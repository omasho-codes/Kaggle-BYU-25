{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":91249,"databundleVersionId":11294684,"sourceType":"competition"},{"sourceId":226368929,"sourceType":"kernelVersion"},{"sourceId":327336,"sourceType":"modelInstanceVersion","modelInstanceId":274744,"modelId":295634},{"sourceId":399430,"sourceType":"modelInstanceVersion","modelInstanceId":326904,"modelId":347800},{"sourceId":399523,"sourceType":"modelInstanceVersion","modelInstanceId":326978,"modelId":347876}],"dockerImageVersionId":30919,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!cp -r /kaggle/input/mhafyolo/pytorch/default/1/MHAF-YOLO-main /kaggle/working/\n\nimport os\nfrom pathlib import Path\n\ncurrent_dir = Path.cwd()\nprint(\"this_dir:\", current_dir)\n\ntarget_dir = Path(\"/kaggle/working/MHAF-YOLO-main\") \nos.chdir(target_dir)  \nmodel_path = \"/kaggle/input/mhaf-m-public/other/default/1/36_data_96_663.pt\"\nCONFIDENCE_THRESHOLD = 0.3\nTRACK_CONFIDENCE_THRESHOLD = 0.47 # NEW: For finalized 3D tracks before NMS\n\nNMS_IOU_THRESHOLD = 0.2 # This will be used for 3D NMS\nCONCENTRATION = 1 # Percentage of slices to process\nBATCH_SIZE = 32 # Batch size for YOLO inference\n\nLINK_IOU_THRESHOLD_2D = 0.3      # For associating 2D boxes across slices\nLINK_MAX_MISSED_SLICES = 1      # Max original slices a track can be missed and still be linked\nLINK_MIN_SLICES_FOR_3D = 3       # Min number of slices a track must span to be a 3D object\nLINK_CONFIDENCE_BOOST_FACTOR = 0.2 # Confidence boost per slice beyond LINK_MIN_SLICES_FOR_3D\n\n\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nimport torch\nimport cv2\nfrom tqdm.notebook import tqdm\nfrom ultralytics import YOLOv10 # Assuming this is correctly installed/available\nimport time\nfrom torch.utils.data import Dataset, DataLoader\n\nnp.random.seed(42)\ntorch.manual_seed(42)\n\ndata_path = \"/kaggle/input/byu-locating-bacterial-flagellar-motors-2025/\"\ntest_dir = os.path.join(data_path, \"test\")\nsubmission_path = \"/kaggle/working/submission.csv\"\n\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu' # Simpler device check\nif device == 'cuda':\n    torch.backends.cudnn.benchmark = True\n    torch.backends.cudnn.deterministic = False # Usually False for speed\n    torch.backends.cuda.matmul.allow_tf32 = True\n    torch.backends.cudnn.allow_tf32 = True\n\n# AMP scaler for inference (no scaling needed for inference with autocast)\n# scaler = torch.cuda.amp.GradScaler(enabled=False) # Not typically used for inference like this\n\nclass GPUProfiler:\n    def __init__(self, name):\n        self.name = name\n        self.start_time = None\n    def __enter__(self):\n        if torch.cuda.is_available(): torch.cuda.synchronize()\n        self.start_time = time.time()\n    def __exit__(self, *args):\n        if torch.cuda.is_available(): torch.cuda.synchronize()\n        elapsed = time.time() - self.start_time\n        # print(f\"[PROFILE] {self.name}: {elapsed:.3f}s\")\n\n\n# ------------- START: 2D-to-3D Linking and 3D NMS Code -------------\ndef xywh_to_xyxy(x_center, y_center, w, h):\n    x_min = x_center - w / 2\n    y_min = y_center - h / 2\n    x_max = x_center + w / 2\n    y_max = y_center + h / 2\n    return x_min, y_min, x_max, y_max\n    # return x_center, y_center, w, h\n\ndef calculate_2d_iou(boxA_xyxy, boxB_xyxy):\n    xA = max(boxA_xyxy[0], boxB_xyxy[0])\n    yA = max(boxA_xyxy[1], boxB_xyxy[1])\n    xB = min(boxA_xyxy[2], boxB_xyxy[2])\n    yB = min(boxA_xyxy[3], boxB_xyxy[3])\n\n    interArea = max(0, xB - xA) * max(0, yB - yA)\n    if interArea == 0:\n        return 0.0\n\n    boxAArea = (boxA_xyxy[2] - boxA_xyxy[0]) * (boxA_xyxy[3] - boxA_xyxy[1])\n    boxBArea = (boxB_xyxy[2] - boxB_xyxy[0]) * (boxB_xyxy[3] - boxB_xyxy[1])\n    \n    iou = interArea / float(boxAArea + boxBArea - interArea)\n    return iou\n\ndef calculate_3d_iou(boxA_3d, boxB_3d):\n    # box_3d: (x_min, y_min, z_min, x_max, y_max, z_max)\n    xA = max(boxA_3d[0], boxB_3d[0])\n    yA = max(boxA_3d[1], boxB_3d[1])\n    zA = max(boxA_3d[2], boxB_3d[2])\n    xB = min(boxA_3d[3], boxB_3d[3])\n    yB = min(boxA_3d[4], boxB_3d[4])\n    zB = min(boxA_3d[5], boxB_3d[5])\n\n    interVolume = max(0, xB - xA) * max(0, yB - yA) * max(0, zB - zA)\n    if interVolume == 0:\n        return 0.0\n\n    boxAVolume = (boxA_3d[3] - boxA_3d[0]) * \\\n                 (boxA_3d[4] - boxA_3d[1]) * \\\n                 (boxA_3d[5] - boxA_3d[2])\n    boxBVolume = (boxB_3d[3] - boxB_3d[0]) * \\\n                 (boxB_3d[4] - boxB_3d[1]) * \\\n                 (boxB_3d[5] - boxB_3d[2])\n    \n    iou = interVolume / float(boxAVolume + boxBVolume - interVolume)\n    return iou\n\nclass Track3D:\n    _next_id = 0 # Class variable for unique track IDs\n    def __init__(self, initial_detection_xywhc, z_index, class_id):\n        # initial_detection_xywhc: (x_center, y_center, w, h, confidence)\n        self.id = Track3D._next_id\n        Track3D._next_id += 1\n        \n        self.class_id = class_id\n        \n        x_min, y_min, x_max, y_max = xywh_to_xyxy(*initial_detection_xywhc[:4])\n        self.boxes_2d_slices = {z_index: (x_min, y_min, x_max, y_max, initial_detection_xywhc[4])} # Store xyxy, conf\n        \n        self.last_seen_z = z_index\n        self.confidences = [initial_detection_xywhc[4]]\n\n    def add_detection(self, detection_xywhc, z_index):\n        # detection_xywhc: (x_center, y_center, w, h, confidence)\n        x_min, y_min, x_max, y_max = xywh_to_xyxy(*detection_xywhc[:4])\n        self.boxes_2d_slices[z_index] = (x_min, y_min, x_max, y_max, detection_xywhc[4])\n        self.last_seen_z = z_index\n        self.confidences.append(detection_xywhc[4])\n\n    def get_last_box_xyxy(self):\n        if not self.boxes_2d_slices: return None\n        return self.boxes_2d_slices[self.last_seen_z][:4] # (x_min, y_min, x_max, y_max)\n\n    def finalize(self, min_slices_for_3d_object, confidence_boost_factor):\n        num_slices_seen = len(self.boxes_2d_slices)\n        if num_slices_seen < min_slices_for_3d_object:\n            return None\n\n        all_x_mins = [box[0] for box in self.boxes_2d_slices.values()]\n        all_y_mins = [box[1] for box in self.boxes_2d_slices.values()]\n        all_x_maxs = [box[2] for box in self.boxes_2d_slices.values()]\n        all_y_maxs = [box[3] for box in self.boxes_2d_slices.values()]\n        \n        final_x_min = np.mean(all_x_mins)\n        final_y_min = np.mean(all_y_mins)\n        final_x_max = np.mean(all_x_maxs)\n        final_y_max = np.mean(all_y_maxs)\n\n        z_coords = sorted(self.boxes_2d_slices.keys())\n        final_z_min = z_coords[0]\n        final_z_max = z_coords[-1]\n\n        avg_2d_conf = np.mean(self.confidences)\n        \n        boost = confidence_boost_factor * max(0, num_slices_seen - min_slices_for_3d_object)\n        final_confidence = min(1.0, avg_2d_conf + boost)\n\n        return (final_x_min, final_y_min, final_z_min,\n                final_x_max, final_y_max, final_z_max,\n                self.class_id, final_confidence)\n\ndef combine_2d_to_3d(all_slice_detections_xywhc, # {z: [(xc,yc,w,h,conf), ...]}\n                     iou_threshold_2d_link, \n                     max_missed_slices,\n                     min_slices_for_3d_object,\n                     confidence_boost_factor,\n                     nms_threshold_3d,\n                    track_confidence_threshold):\n    Track3D._next_id = 0 # Reset track ID counter for each tomogram\n    active_tracks = []\n    completed_tracks = []\n\n    sorted_z_indices = sorted(all_slice_detections_xywhc.keys())\n\n    for z_idx_current_slice in sorted_z_indices:\n        detections_in_current_slice = all_slice_detections_xywhc.get(z_idx_current_slice, [])\n        # Assuming detections_in_current_slice = [(xc,yc,w,h, class_id_from_yolo, conf), ...]\n        # For this problem, class_id is fixed (e.g., 0)\n        \n        # Convert current slice detections (xc,yc,w,h,conf) to (xyxy, class_id, conf, original_det_xywhc)\n        current_slice_processed_dets = []\n        for det_xywhc_conf in detections_in_current_slice:\n            # det_xywhc_conf is (xc, yc, w, h, cls_id, conf) where cls_id is the one from YOLO.\n            # We'll use a fixed class_id for tracking if it's single-class problem.\n            xc, yc, w, h, yolo_cls_id, conf = det_xywhc_conf # Assuming this structure\n            det_xyxy = xywh_to_xyxy(xc, yc, w, h)\n            # For single class motor detection, track_class_id will be 0.\n            # If YOLO gives multiple classes, yolo_cls_id would be used.\n            track_class_id = 0 # Use fixed class for motors.\n            current_slice_processed_dets.append(\n                (det_xyxy, track_class_id, conf, (xc,yc,w,h,conf)) # Pass (xc,yc,w,h,conf) for Track3D\n            )\n\n        matched_to_track_this_slice = [False] * len(current_slice_processed_dets)\n        \n        for track_idx in range(len(active_tracks) -1, -1, -1): # Iterate backwards for safe removal\n            track = active_tracks[track_idx]\n            \n            # Terminate old tracks before matching\n            if z_idx_current_slice - track.last_seen_z > max_missed_slices:\n                completed_tracks.append(active_tracks.pop(track_idx))\n                continue\n\n            best_match_local_idx = -1 # Index within current_slice_processed_dets\n            max_iou = 0.0\n            track_last_box_xyxy = track.get_last_box_xyxy()\n            if track_last_box_xyxy is None: continue\n\n            for det_idx, (det_xyxy, det_cls, _, _) in enumerate(current_slice_processed_dets):\n                if matched_to_track_this_slice[det_idx]: continue\n                \n                if det_cls == track.class_id: # Class matching\n                    iou = calculate_2d_iou(track_last_box_xyxy, det_xyxy)\n                    if iou > iou_threshold_2d_link and iou > max_iou:\n                        max_iou = iou\n                        best_match_local_idx = det_idx\n            \n            if best_match_local_idx != -1:\n                original_det_xywhc_conf_for_track = current_slice_processed_dets[best_match_local_idx][3]\n                track.add_detection(original_det_xywhc_conf_for_track, z_idx_current_slice)\n                matched_to_track_this_slice[best_match_local_idx] = True\n        \n        for det_idx, (det_xyxy, det_cls, det_conf, original_det_xywhc_conf) in enumerate(current_slice_processed_dets):\n            if not matched_to_track_this_slice[det_idx]:\n                # original_det_xywhc_conf is (xc,yc,w,h,conf)\n                active_tracks.append(Track3D(original_det_xywhc_conf, z_idx_current_slice, det_cls))\n                \n    completed_tracks.extend(active_tracks)\n\n    pre_nms_3d_boxes = []\n    for track in completed_tracks:\n        final_box_3d = track.finalize(min_slices_for_3d_object, confidence_boost_factor)\n        if final_box_3d:\n            if final_box_3d[7] >= track_confidence_threshold :\n                pre_nms_3d_boxes.append(final_box_3d)\n\n    if not pre_nms_3d_boxes: return []\n\n    pre_nms_3d_boxes = sorted(pre_nms_3d_boxes, key=lambda x: x[7], reverse=True) # Sort by confidence (idx 7)\n    \n    final_preds_3d = []\n    while pre_nms_3d_boxes:\n        current_box = pre_nms_3d_boxes.pop(0)\n        final_preds_3d.append(current_box)\n        \n        remaining_boxes_after_nms = []\n        for box_to_compare in pre_nms_3d_boxes:\n            if current_box[6] != box_to_compare[6]: # Different class, keep (NMS is class-specific)\n                 remaining_boxes_after_nms.append(box_to_compare)\n                 continue\n            iou_3d = calculate_3d_iou(current_box[:6], box_to_compare[:6])\n            if iou_3d < nms_threshold_3d:\n                remaining_boxes_after_nms.append(box_to_compare)\n        pre_nms_3d_boxes = remaining_boxes_after_nms\n        \n    return final_preds_3d\n# ------------- END: 2D-to-3D Linking and 3D NMS Code -------------\n\n\nclass TomogramSliceDataset(Dataset):\n    def __init__(self, paths):\n        self.paths = paths\n    def __len__(self):\n        return len(self.paths)\n    def __getitem__(self, idx):\n        p = self.paths[idx]\n        img = cv2.imread(str(p)) # Path object to string\n        if img is None:\n            print(f\"Warning: Failed to read image {p}. Using a placeholder.\")\n            # Placeholder: a black image of a common size, e.g., 960x960x3\n            # You might need to know the expected dimensions from other images.\n            # For now, let's assume this won't happen or use a fixed size.\n            # This should ideally raise an error or be handled based on competition rules.\n            return np.zeros((960, 960, 3), dtype=np.uint8), -1 # Invalid slice_num\n\n        # img = cv2.medianBlur(img, ksize=5)\n        \n        try:\n            slice_num = int(Path(p).stem.split('_')[1])\n        except (IndexError, ValueError):\n            print(f\"Warning: Could not parse slice number from {Path(p).stem}. Using -1.\")\n            slice_num = -1 # Indicates an error or unexpected format\n            \n        return img, slice_num\n\n    @staticmethod\n    def collate_fn(batch):\n        imgs, slice_nums_batch = zip(*batch)\n        # Filter out any images that failed to load properly (where slice_num might be -1)\n        valid_batch = [(img, sn) for img, sn in zip(imgs, slice_nums_batch) if sn != -1]\n        if not valid_batch:\n            return [], [] # Return empty lists if all images in batch failed\n        \n        valid_imgs, valid_slice_nums = zip(*valid_batch)\n        return list(valid_imgs), list(valid_slice_nums)\n\n\n@torch.no_grad()\ndef process_tomogram(tomo_id, model, \n                     link_iou_thresh, link_max_missed, \n                     link_min_slices, link_conf_boost, \n                     final_nms_iou_3d,\n                    track_confidence_thresh): # Removed total, idx as they were for tqdm\n    \n    tomo_path = Path(test_dir) / tomo_id\n    files_all = sorted([f for f in tomo_path.glob('*.jpg')]) # Use Path.glob\n\n    num_total_slices = len(files_all)\n    if num_total_slices == 0:\n        return {'tomo_id': tomo_id, 'Motor axis 0': -1, 'Motor axis 1': -1, 'Motor axis 2': -1}\n\n    num_selected_slices = int(num_total_slices * CONCENTRATION)\n    if num_selected_slices == 0: num_selected_slices = 1 # Ensure at least one slice if CONCENTRATION is too low but files exist\n    \n    if num_selected_slices == 1:\n        sel_indices = [num_total_slices // 2] # Middle slice\n    else:\n        sel_indices = np.linspace(0, num_total_slices - 1, num_selected_slices).round().astype(int)\n    \n    sel_indices = np.unique(sel_indices)\n    paths = [files_all[i] for i in sel_indices]\n\n    if not paths:\n        return {'tomo_id': tomo_id, 'Motor axis 0': -1, 'Motor axis 1': -1, 'Motor axis 2': -1}\n\n    ds = TomogramSliceDataset(paths)\n    # Determine num_workers based on available CPUs, max 4 as in original\n    num_workers = min(4, os.cpu_count() if os.cpu_count() else 1)\n    loader = DataLoader(ds, batch_size=BATCH_SIZE, shuffle=False,\n                        num_workers=num_workers, pin_memory=True,\n                        collate_fn=TomogramSliceDataset.collate_fn)\n\n    # {slice_num: [(xc, yc, w, h, yolo_class_id, confidence), ...]}\n    detections_for_3d_linking = {} \n\n    for imgs_batch, slice_nums_batch in loader:\n        if not imgs_batch: continue # Skip if batch is empty (e.g., all images failed to load)\n\n        with GPUProfiler(f\"Inference {len(imgs_batch)} slices for {tomo_id}\"):\n            # YOLOv10 expects a list of numpy arrays or PIL images.\n            # imgs_batch should already be in this format from cv2.imread\n            with torch.cuda.amp.autocast(enabled=(device == 'cuda')):\n                preds = model(imgs_batch, verbose=False) \n        \n        for i, result in enumerate(preds):\n            actual_z_slice_num = slice_nums_batch[i]\n            if actual_z_slice_num == -1: continue # Skip if slice num parsing failed for this image\n\n            if len(result.boxes) > 0:\n                for box_idx in range(len(result.boxes)):\n                    conf = float(result.boxes.conf[box_idx])\n                    if conf >= CONFIDENCE_THRESHOLD:\n                        box_xyxy = result.boxes.xyxy[box_idx].cpu().numpy()\n                        # yolo_class_id = int(result.boxes.cls[box_idx].cpu()) # If model is multi-class\n                        yolo_class_id = 0 # For this single-class problem\n\n                        x1, y1, x2, y2 = box_xyxy\n                        xc = (x1 + x2) / 2\n                        yc = (y1 + y2) / 2\n                        w = abs(x2 - x1)\n                        h = abs(y2 - y1)\n\n                        if w == 0 or h == 0: continue\n\n                        if actual_z_slice_num not in detections_for_3d_linking:\n                            detections_for_3d_linking[actual_z_slice_num] = []\n                        detections_for_3d_linking[actual_z_slice_num].append(\n                            (xc, yc, w, h, yolo_class_id, conf)\n                        )\n    \n    final_3d_predictions = combine_2d_to_3d(\n        detections_for_3d_linking,\n        iou_threshold_2d_link=link_iou_thresh,\n        max_missed_slices=link_max_missed,\n        min_slices_for_3d_object=link_min_slices,\n        confidence_boost_factor=link_conf_boost,\n        nms_threshold_3d=final_nms_iou_3d ,\n        track_confidence_threshold=track_confidence_thresh\n    )\n\n    if not final_3d_predictions:\n        return {'tomo_id': tomo_id, 'Motor axis 0': -1,\n                'Motor axis 1': -1, 'Motor axis 2': -1}\n    \n    best_3d_pred = final_3d_predictions[0] # Already sorted by confidence\n    \n    pred_x_min, pred_y_min, pred_z_min, \\\n    pred_x_max, pred_y_max, pred_z_max, _, _ = best_3d_pred\n\n    final_z = int(round((pred_z_min + pred_z_max) / 2))\n    final_y = int(round((pred_y_min + pred_y_max) / 2))\n    final_x = int(round((pred_x_min + pred_x_max) / 2))\n        \n    return {'tomo_id': tomo_id,\n            'Motor axis 0': final_z,\n            'Motor axis 1': final_y,\n            'Motor axis 2': final_x}\n\n\ndef generate_submission():\n    tomos = sorted([d.name for d in Path(test_dir).iterdir() if d.is_dir()])\n    \n    # It's critical that MHAF-YOLO specific files are accessible if YOLOv10(model_path)\n    # relies on them being in the current working directory or a specific structure.\n    # If YOLOv10 loads a .pt file and that's self-contained, os.chdir might not be strictly necessary\n    # for model loading itself, but could be for other utilities from MHAF-YOLO repo if used.\n    # The provided script changes dir, so we assume it's needed.\n    # Ensure MHAF-YOLO setup (like !cp and os.chdir) is done *before* this function if model loading depends on it.\n    # Re-checking the os.chdir logic at the top of the script.\n    \n    print(f\"Loading model from: {model_path}\")\n    model = YOLOv10(model_path) # Ensure MHAF-YOLO is in path or CWD if needed\n    model.to(device)\n    \n    if device == 'cuda':\n        # model.fuse() # Fuse layers for potential speedup, check if compatible\n        if hasattr(model,'fuse'): model.fuse()\n        \n        # Half precision if supported and beneficial\n        # if torch.cuda.get_device_capability(0)[0] >= 7: # Check for Volta or newer for good FP16 support\n        #     model.half() # model.model.half() in original\n        #     # Note: autocast handles mixed precision, so explicit .half() might not be needed\n        #     # or could conflict if autocast is also used. Test this.\n        #     # If using model.half(), autocast should often be disabled or used carefully.\n        #     # Given autocast is used, explicit .half() might be redundant or counterproductive.\n        #     # Let's rely on autocast.\n        pass\n\n\n    results = []\n    for tomo_id in tqdm(tomos, desc=\"Processing Tomograms\"):\n        if device == 'cuda': torch.cuda.empty_cache()\n        res = process_tomogram(\n            tomo_id, model,\n            LINK_IOU_THRESHOLD_2D,\n            LINK_MAX_MISSED_SLICES,\n            LINK_MIN_SLICES_FOR_3D,\n            LINK_CONFIDENCE_BOOST_FACTOR,\n            NMS_IOU_THRESHOLD,\n            TRACK_CONFIDENCE_THRESHOLD # This is the 3D NMS threshold from global const\n        )\n        results.append(res)\n\n    df = pd.DataFrame(results)[['tomo_id','Motor axis 0','Motor axis 1','Motor axis 2']]\n    df.to_csv(submission_path, index=False)\n    print(\"\\nSubmission file created:\")\n    print(df.head())\n    return df\n\nif __name__ == \"__main__\":\n    start_time = time.time()\n    generate_submission()\n    end_time = time.time()\n    print(f\"\\nTotal processing time: {end_time - start_time:.2f} seconds\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-31T09:40:29.388920Z","iopub.execute_input":"2025-05-31T09:40:29.389287Z","iopub.status.idle":"2025-05-31T09:41:59.855934Z","shell.execute_reply.started":"2025-05-31T09:40:29.389241Z","shell.execute_reply":"2025-05-31T09:41:59.854817Z"}},"outputs":[{"name":"stdout","text":"this_dir: /kaggle/working\nLoading model from: /kaggle/input/mhaf-m-public/other/default/1/36_data_96_663.pt\n","output_type":"stream"},{"name":"stderr","text":"/kaggle/working/MHAF-YOLO-main/ultralytics/nn/tasks.py:751: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  ckpt = torch.load(file, map_location=\"cpu\")\n","output_type":"stream"},{"name":"stdout","text":"Switch model to UniRepLKNetBlock\nSwitch model to UniRepLKNetBlock\nSwitch model to UniRepLKNetBlock\nSwitch model to UniRepLKNetBlock\nSwitch model to UniRepLKNetBlock\nSwitch model to UniRepLKNetBlock\nSwitch model to UniRepLKNetBlock\nSwitch model to UniRepLKNetBlock\nSwitch model to UniRepLKNetBlock\nSwitch model to UniRepLKNetBlock\nSwitch model to UniRepLKNetBlock\nSwitch model to UniRepLKNetBlock\nSwitch model to UniRepLKNetBlock\nSwitch model to UniRepLKNetBlock\nSwitch model to UniRepLKNetBlock\nSwitch model to UniRepLKNetBlock\nSwitch model to UniRepLKNetBlock\nSwitch model to UniRepLKNetBlock\nSwitch model to UniRepLKNetBlock\nSwitch model to UniRepLKNetBlock\nSwitch model to UniRepLKNetBlock\nSwitch model to UniRepLKNetBlock\nSwitch model to UniRepLKNetBlock\nSwitch model to UniRepLKNetBlock\nSwitch model to UniRepLKNetBlock\nSwitch model to UniRepLKNetBlock\nSwitch model to UniRepLKNetBlock\nSwitch model to UniRepLKNetBlock\nSwitch model to UniRepLKNetBlock\nSwitch model to UniRepLKNetBlock\nSwitch model to UniRepLKNetBlock\nSwitch model to UniRepLKNetBlock\nSwitch model to UniRepLKNetBlock\nSwitch model to UniRepLKNetBlock\nSwitch model to UniRepLKNetBlock\nSwitch model to UniRepLKNetBlock\nSwitch model to UniRepLKNetBlock\nSwitch model to UniRepLKNetBlock\nSwitch model to UniRepLKNetBlock\nSwitch model to UniRepLKNetBlock\nSwitch model to UniRepLKNetBlock\nSwitch model to UniRepLKNetBlock\nSwitch model to UniRepLKNetBlock\nSwitch model to UniRepLKNetBlock\nSwitch model to UniRepLKNetBlock\nSwitch model to UniRepLKNetBlock\nSwitch model to UniRepLKNetBlock\nSwitch model to UniRepLKNetBlock\nSwitch model to UniRepLKNetBlock\nSwitch model to UniRepLKNetBlock\nMAF-YOLOv10m-v2 summary: 838 layers, 15799254 parameters, 824896 gradients\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Processing Tomograms:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"94c14ffb0ce14a73a079a764828ee011"}},"metadata":{}},{"name":"stdout","text":"Switch model to UniRepLKNetBlock\nSwitch model to UniRepLKNetBlock\nSwitch model to UniRepLKNetBlock\nSwitch model to UniRepLKNetBlock\nSwitch model to UniRepLKNetBlock\nSwitch model to UniRepLKNetBlock\nSwitch model to UniRepLKNetBlock\nSwitch model to UniRepLKNetBlock\nSwitch model to UniRepLKNetBlock\nSwitch model to UniRepLKNetBlock\nSwitch model to UniRepLKNetBlock\nSwitch model to UniRepLKNetBlock\nSwitch model to UniRepLKNetBlock\nSwitch model to UniRepLKNetBlock\nSwitch model to UniRepLKNetBlock\nSwitch model to UniRepLKNetBlock\nSwitch model to UniRepLKNetBlock\nSwitch model to UniRepLKNetBlock\nSwitch model to UniRepLKNetBlock\nSwitch model to UniRepLKNetBlock\nSwitch model to UniRepLKNetBlock\nSwitch model to UniRepLKNetBlock\nSwitch model to UniRepLKNetBlock\nSwitch model to UniRepLKNetBlock\nSwitch model to UniRepLKNetBlock\nSwitch model to UniRepLKNetBlock\nSwitch model to UniRepLKNetBlock\nSwitch model to UniRepLKNetBlock\nSwitch model to UniRepLKNetBlock\nSwitch model to UniRepLKNetBlock\nSwitch model to UniRepLKNetBlock\nSwitch model to UniRepLKNetBlock\nSwitch model to UniRepLKNetBlock\nSwitch model to UniRepLKNetBlock\nSwitch model to UniRepLKNetBlock\nSwitch model to UniRepLKNetBlock\nSwitch model to UniRepLKNetBlock\nSwitch model to UniRepLKNetBlock\nSwitch model to UniRepLKNetBlock\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-1-6a480f59dfd0>:348: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=(device == 'cuda')):\n","output_type":"stream"},{"name":"stdout","text":"Switch model to UniRepLKNetBlock\nSwitch model to UniRepLKNetBlock\nSwitch model to UniRepLKNetBlock\nSwitch model to UniRepLKNetBlock\nSwitch model to UniRepLKNetBlock\nSwitch model to UniRepLKNetBlock\nSwitch model to UniRepLKNetBlock\nSwitch model to UniRepLKNetBlock\nSwitch model to UniRepLKNetBlock\nSwitch model to UniRepLKNetBlock\nSwitch model to UniRepLKNetBlock\n\nSubmission file created:\n       tomo_id  Motor axis 0  Motor axis 1  Motor axis 2\n0  tomo_003acc            -1            -1            -1\n1  tomo_00e047           168           546           602\n2  tomo_01a877           146           638           285\n\nTotal processing time: 74.85 seconds\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# !cp -r /kaggle/input/mhafyolo/pytorch/default/1/MHAF-YOLO-main /kaggle/working/\n\n# model_path = \"/kaggle/input/mhaf-m-public/other/default/1/36_data_96_663.pt\"\n# CONFIDENCE_THRESHOLD = 0.35\n# MAX_DETECTIONS_PER_TOMO = 1\n# NMS_IOU_THRESHOLD = 0.2\n# CONCENTRATION = 0.5\n# BATCH_SIZE = 8 \n\n# import os\n# from pathlib import Path\n\n# current_dir = Path.cwd()\n# print(\"this_dir:\", current_dir)\n\n# target_dir = Path(\"/kaggle/working/MHAF-YOLO-main\") \n# os.chdir(target_dir)  \n\n# import os\n# import numpy as np\n# import pandas as pd\n# from PIL import Image\n# import torch\n# import cv2\n# from tqdm.notebook import tqdm\n# from ultralytics import YOLOv10\n# import threading\n# import time\n# from contextlib import nullcontext\n# from concurrent.futures import ThreadPoolExecutor\n\n# from pathlib import Path\n\n# from torch.utils.data import Dataset, DataLoader\n# from torch.utils.data import DataLoader, TensorDataset\n\n\n\n# np.random.seed(42)\n# torch.manual_seed(42)\n\n\n# data_path = \"/kaggle/input/byu-locating-bacterial-flagellar-motors-2025/\"\n# test_dir = os.path.join(data_path, \"test\")\n# submission_path = \"/kaggle/working/submission.csv\"\n\n# device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n# if device.startswith('cuda'):\n#     torch.backends.cudnn.benchmark = True\n#     torch.backends.cudnn.deterministic = False\n#     torch.backends.cuda.matmul.allow_tf32 = True\n#     torch.backends.cudnn.allow_tf32 = True\n\n# # AMP scaler for inference (no scaling)\n# scaler = torch.cuda.amp.GradScaler(enabled=False)\n\n# class GPUProfiler:\n#     def __init__(self, name):\n#         self.name = name\n#         self.start_time = None\n#     def __enter__(self):\n#         if torch.cuda.is_available(): torch.cuda.synchronize()\n#         self.start_time = time.time()\n#     def __exit__(self, *args):\n#         if torch.cuda.is_available(): torch.cuda.synchronize()\n#         elapsed = time.time() - self.start_time\n#         # print(f\"[PROFILE] {self.name}: {elapsed:.3f}s\")\n\n\n# def perform_3d_nms(detections, iou_threshold):\n#     \"\"\"\n#     Perform 3D Non-Maximum Suppression on detections to merge nearby motors\n#     \"\"\"\n#     if not detections:\n#         return []\n    \n#     # Sort by confidence (highest first)\n#     detections = sorted(detections, key=lambda x: x['confidence'], reverse=True)\n    \n#     # List to store final detections after NMS\n#     final_detections = []\n    \n#     # Define 3D distance function\n#     def distance_3d(d1, d2):\n#         return np.sqrt((d1['z'] - d2['z'])**2 + \n#                        (d1['y'] - d2['y'])**2 + \n#                        (d1['x'] - d2['x'])**2)\n    \n#     # Maximum distance threshold (based on box size and slice gap)\n#     box_size = 24  # Same as annotation box size\n#     distance_threshold = box_size * iou_threshold\n    \n#     # Process each detection\n#     while detections:\n#         # Take the detection with highest confidence\n#         best_detection = detections.pop(0)\n#         final_detections.append(best_detection)\n#         return final_detections\n#     #     # Filter out detections that are too close to the best detection\n#         # detections = [d for d in detections if distance_3d(d, best_detection) > distance_threshold]\n    \n#     return final_detections\n\n\n# class TomogramSliceDataset(Dataset):\n#     def __init__(self, paths, target_size=(960,960)):\n#         self.paths = paths\n#         self.target_size = target_size\n#     def __len__(self):\n#         return len(self.paths)\n#     def __getitem__(self, idx):\n#         p = self.paths[idx]\n#         img = cv2.imread(p)\n#         if img is None:\n#             img = np.array(Image.open(p))\n#         # Resize to target size to limit GPU memory usage\n#         # img = cv2.resize(img, self.target_size, interpolation=cv2.INTER_AREA)\n#         # img = torch.from_numpy(img)\n#         return idx, img\n\n#     @staticmethod\n#     def collate_fn(batch):\n#         paths, imgs = zip(*batch)\n#         return list(paths), list(imgs)\n\n\n\n# @torch.no_grad()\n# def process_tomogram(tomo_id, model, total, idx):\n#     tomo_path = os.path.join(test_dir, tomo_id)\n#     files = sorted([f for f in os.listdir(tomo_path) if f.endswith('.jpg')])\n#     sel = np.linspace(0, len(files)-1, int(len(files)*CONCENTRATION)).round().astype(int)\n#     files = [files[i] for i in sel]\n#     paths = [os.path.join(tomo_path, f) for f in files]\n#     slice_nums = [int(f.split('_')[1].split('.')[0]) for f in files]\n\n#     ds = TomogramSliceDataset(paths)\n#     loader = DataLoader(ds, batch_size=32, shuffle=False,\n#                         num_workers=4, pin_memory=True,\n#                         collate_fn=TomogramSliceDataset.collate_fn)\n\n#     all_dets = []\n#     # volm = []\n#     for batch_zidx, imgs in loader:\n#         with GPUProfiler(f\"Inference {len(batch_zidx)} slices\"):\n#             with torch.cuda.amp.autocast():\n#                 preds = model(imgs, verbose=False)\n        \n#         # imgs = np.concatenate(imgs, axis=0)\n#         # (B,H, W) = im/gs.shape\n#         # volm.append(imgs.reshape(-1, H, W))\n#         for z, result in zip(batch_zidx, preds):\n#             z = slice_nums.pop(0)\n#             if len(result.boxes) > 0 and result.boxes.conf[0] >= CONFIDENCE_THRESHOLD :\n#                 x1,y1,x2,y2 = result.boxes.xyxy[0].cpu().numpy()\n#                 all_dets.append({\n#                             'z': z,\n#                             'y': int(round((y1+y2)/2)),\n#                             'x': int(round((x1+x2)/2)),\n#                             'confidence': float(result.boxes.conf[0])\n#                         })\n           \n#     # if device.startswith('cuda'): torch.cuda.synchronize()\n#     final = perform_3d_nms(all_dets, NMS_IOU_THRESHOLD)\n#     # final.sort(key=lambda x: x['confidence'], reverse=True)\n#     if not final:\n#         return {'tomo_id': tomo_id, 'Motor axis 0': -1,\n#                 'Motor axis 1': -1, 'Motor axis 2': -1}\n        \n#     # if len(all_dets)<3:\n#     #     return {'tomo_id': tomo_id, 'Motor axis 0': -1,\n#     #             'Motor axis 1': -1, 'Motor axis 2': -1}\n        \n#     best = final[0]\n#     return {'tomo_id': tomo_id,\n#             'Motor axis 0': best['z'],\n#             'Motor axis 1': best['y'],\n#             'Motor axis 2': best['x']}\n\n\n# def generate_submission():\n#     tomos = sorted([d for d in os.listdir(test_dir) if os.path.isdir(os.path.join(test_dir, d))])\n#     model = YOLOv10(model_path)\n#     model.to(device)\n#     if device.startswith('cuda'):\n#         model.fuse()\n#         if torch.cuda.get_device_capability(0)[0] >= 7:\n#             model.model.half()\n\n#     results = []\n#     for idx, tomo in enumerate(tqdm(tomos, desc=\"Tomo loop\"), 1):\n#         torch.cuda.empty_cache()\n#         res = process_tomogram(tomo, model, len(tomos), idx)\n#         results.append(res)\n\n#     df = pd.DataFrame(results)[['tomo_id','Motor axis 0','Motor axis 1','Motor axis 2']]\n#     df.to_csv(submission_path, index=False)\n#     print(df.head())\n#     return df\n\n# if __name__ == \"__main__\":\n#     start = time.time()\n#     generate_submission()\n#     print(f\"Total time: {time.time()-start:.2f}s\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-28T10:08:37.013462Z","iopub.execute_input":"2025-05-28T10:08:37.013693Z","iopub.status.idle":"2025-05-28T10:09:50.976711Z","shell.execute_reply.started":"2025-05-28T10:08:37.013671Z","shell.execute_reply":"2025-05-28T10:09:50.97566Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}